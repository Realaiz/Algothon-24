{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "from talib import WMA, RSI, MACD, BBANDS\n",
    "from itertools import product\n",
    "import warnings\n",
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo/anaconda3/lib/python3.11/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import spearmanr\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from time import time\n",
    "from lightgbm import log_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPrices(fn):\n",
    "    global nt, nInst\n",
    "    df = pd.read_csv(fn, sep=\"\\s+\", header=None, index_col=None)\n",
    "    (nt, nInst) = df.shape\n",
    "    return (df.values).T\n",
    "\n",
    "\n",
    "pricesFile = \"./prices.txt\"\n",
    "prcAll = loadPrices(pricesFile)\n",
    "\n",
    "prcHistT = pd.DataFrame(prcAll.T)\n",
    "\n",
    "variance = prcHistT.var()\n",
    "stdev = np.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simPrices(prcHist):\n",
    "    n = 252\n",
    "    t = 1\n",
    "    tau = t / n\n",
    "    prcHist = pd.DataFrame(prcHist.T)\n",
    "    returns = prcHist.pct_change()\n",
    "\n",
    "    sigma = returns.iloc[:-500, :].std()\n",
    "\n",
    "    mean = returns.mean()\n",
    "    mu = mean - (0.5 * sigma**2)\n",
    "    print(mean)\n",
    "    S = prcHist.iloc[-1, :]\n",
    "    simmedPrices = np.zeros((n, len(prcHist.columns)))\n",
    "    simmedPrices[0, :] = S\n",
    "\n",
    "    for i in range(1, n):\n",
    "        Z = np.random.normal(0, 1)\n",
    "        # Simulate log prices\n",
    "        simmedPrices[i, :] = simmedPrices[i - 1, :] + (mu*simmedPrices[i - 1, :]) + (sigma*simmedPrices[i - 1, :]*Z)\n",
    "\n",
    "    # Convert simulated log prices back to normal prices\n",
    "    simmedPrices = pd.DataFrame(simmedPrices)\n",
    "\n",
    "    return simmedPrices\n",
    "\n",
    "\n",
    "simulated_prices = simPrices(prcAll).T\n",
    "prcFull = pd.concat([pd.DataFrame(prcAll), pd.DataFrame(simulated_prices)], axis=1, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_features(prcSoFar): \n",
    "  data = pd.DataFrame()\n",
    "  lags = [1, 5, 21, 42, 63, 126, 189, 252]\n",
    "  for lag in lags:\n",
    "    data[f'return_{lag}d'] = (prcSoFar\n",
    "      .pct_change(lag, fill_method=None)\n",
    "      .stack()\n",
    "      .pipe(lambda x: x.clip(lower=x.quantile(0.01),\n",
    "        upper=x.quantile(0.99)))\n",
    "    )\n",
    "\n",
    "  for lag in [42,63,126,189,252]: ##momentum diff indicators\n",
    "    data[f'momentum_{lag//21}'] = data[f'return_{lag}d'].sub(data.return_21d)\n",
    "  data[f'momentum_3_12'] = data[f'return_252d'].sub(data.return_63d)\n",
    "\n",
    "  for t in [1, 5, 21]:  # target returns\n",
    "    data[f'r{t}_fwd'] = data.groupby(level=0)[f'return_{t}d'].shift(-t)\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi(prices):\n",
    "    return prices.apply(RSI)\n",
    "\n",
    "\n",
    "def bollinger(prices):\n",
    "    # Initialize dictionaries to hold the high and low Bollinger Bands for each column\n",
    "    bb_high = {}\n",
    "    bb_low = {}\n",
    "\n",
    "    # Apply BBANDS to each column in the DataFrame\n",
    "    for column in prices.columns:\n",
    "        high, mid, low = BBANDS(prices[column].values, timeperiod=20)\n",
    "        bb_high[column] = high\n",
    "        bb_low[column] = low\n",
    "\n",
    "    # Convert the dictionaries to DataFrames\n",
    "    bb_high_df = pd.DataFrame(bb_high, index=prices.index)\n",
    "    bb_low_df = pd.DataFrame(bb_low, index=prices.index)\n",
    "\n",
    "    # Combine the high and low Bollinger Bands into a single DataFrame\n",
    "    bollinger_bands = pd.concat(\n",
    "        [bb_high_df, bb_low_df], axis=1, keys=[\"bb_high\", \"bb_low\"]\n",
    "    )\n",
    "\n",
    "    return bollinger_bands\n",
    "\n",
    "\n",
    "def macd(prices):\n",
    "    def compute_macd(close):\n",
    "        macd, macd_signal, macd_hist = MACD(close)\n",
    "        return (macd - np.nanmean(macd)) / np.nanstd(macd)\n",
    "\n",
    "    macd_df = prices.apply(lambda col: compute_macd(col.values), axis=0)\n",
    "    return macd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(df):\n",
    "    return np.log1p(df)\n",
    "def sign(df):\n",
    "    return np.sign(df)\n",
    "def power(df, exp):\n",
    "    return df.pow(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(df: pd.DataFrame)-> pd.DataFrame:\n",
    "  return df.rank(axis=1, pct=True)\n",
    "\n",
    "def scale(df: pd.DataFrame)-> pd.DataFrame:\n",
    "  return df.div(df.abs().sum(axis=1), axis=0)\n",
    "\n",
    "def lagged_ts(df: pd.DataFrame, t: int = 1)-> pd.DataFrame:\n",
    "  return df.shift(t)\n",
    "\n",
    "def diff_ts(df: pd.DataFrame, period: int = 1)-> pd.DataFrame:\n",
    "  return df.diff(period)\n",
    "\n",
    "def rollingsum_ts(df: pd.DataFrame, window: int = 10)-> pd.DataFrame:\n",
    "  return df.rolling(window).sum()\n",
    "\n",
    "def rollingmean_ts(df: pd.DataFrame, window: int = 10)-> pd.DataFrame:\n",
    "  return df.rolling(window).mean()\n",
    "\n",
    "def rollingweightedmean_ts(df: pd.DataFrame, period: int = 10)-> pd.DataFrame:\n",
    "  return df.apply(lambda x: WMA(x, timeperiod=period))\n",
    "\n",
    "def rollingstd_ts(df: pd.DataFrame, window: int = 10)-> pd.DataFrame:\n",
    "  return df.rolling(window).std()\n",
    "\n",
    "def rollingrank_ts(df: pd.DataFrame, window: int = 10)-> pd.DataFrame:\n",
    "  return df.rolling(window).apply(lambda x: x.rank().iloc[-1])\n",
    "\n",
    "def rollingproduct_ts(df: pd.DataFrame, window: int = 10)-> pd.DataFrame:\n",
    "  return df.rolling(window).apply(np.prod)\n",
    "\n",
    "def rollingmin_ts(df: pd.DataFrame, window: int = 10)-> pd.DataFrame:\n",
    "  return df.rolling(window).min()\n",
    "\n",
    "def rollingmax_ts(df: pd.DataFrame, window: int = 10)-> pd.DataFrame:\n",
    "  return df.rolling(window).max()\n",
    "\n",
    "def maxdate_ts(df: pd.DataFrame, window: int = 10)-> pd.DataFrame:\n",
    "  return df.rolling(window).apply(np.argmax).add(1)\n",
    "\n",
    "def mindate_ts(df: pd.DataFrame, window: int = 10)->pd.DataFrame:\n",
    "  return df.rolling(window).apply(np.argmin).add(1)\n",
    "\n",
    "def rollingcorr_ts(x: pd.Series, y: pd.Series, window: int = 10)-> pd.DataFrame:\n",
    "    return x.rolling(window).corr(y)\n",
    "\n",
    "def rollingcov_ts(x: pd.Series, y: pd.Series, window: int = 10) -> pd.DataFrame:\n",
    "    return x.rolling(window).cov(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha1(prices, returns): #1\n",
    "  prices = prices.copy()\n",
    "  returns = returns.shift(1)\n",
    "  prices[returns < 0] = rollingstd_ts(returns, 20)\n",
    "  return (rank(maxdate_ts(power(prices, 2), 5)).mul(-0.5))\n",
    "\n",
    "def alpha2(prices): #4\n",
    "  return (-1* rollingrank_ts(rank(prices), 9))\n",
    "\n",
    "def alpha3(prices): #9\n",
    "  prices_diff = diff_ts(prices, 1)\n",
    "  return prices_diff.where(rollingmin_ts(prices_diff, 5) > 0, prices_diff.where(rollingmax_ts(prices_diff, 5) < 0,-prices_diff))\n",
    "\n",
    "def alpha4(prices): #10\n",
    "  prices_diff = diff_ts(prices, 1)\n",
    "  return prices_diff.where(rollingmin_ts(prices_diff, 4) > 0, prices_diff.where(rollingmin_ts(prices_diff, 4) > 0, -prices_diff))\n",
    "\n",
    "def alpha5(prices): #23\n",
    "  return diff_ts(prices, 2).mul(-1).where(rollingmean_ts(prices, 20) < prices, 0)\n",
    "\n",
    "def alpha6(prices): #24\n",
    "  cond = diff_ts(rollingmean_ts(prices, 100), 100) / lagged_ts(prices, 100) <= 0.05\n",
    "  return prices.sub(rollingmin_ts(prices, 100)).mul(-1).where(cond, -diff_ts(prices, 3))\n",
    "\n",
    "def alpha7(prices, returns): #29\n",
    "  return rollingmin_ts(rank(rank(scale(log(rollingsum_ts(rank(rank(-rank(diff_ts((prices - 1), 5)))), 2))))), 5).add(rollingrank_ts(lagged_ts((-1*returns), 6), 5))\n",
    "\n",
    "def alpha8(prices, returns): #34\n",
    "  return rank(rank(rollingstd_ts(returns, 2).div(rollingstd_ts(returns, 5)).replace([-np.inf, np.inf], np.nan)).mul(-1).sub(rank(diff_ts(prices, 1))).add(2))\n",
    " \n",
    "def alpha9(prices): #46\n",
    "  cond = lagged_ts(diff_ts(prices, 10), 10).div(10).sub(diff_ts(prices, 10).div(10))\n",
    "  alpha = pd.DataFrame(-np.ones_like(cond), index=prices.index, columns=prices.columns)\n",
    "  alpha[cond.isnull()] = np.nan\n",
    "  return cond.where(cond > 0.25, -alpha.where(cond < 0, -diff_ts(prices, 1)))\n",
    "\n",
    "def alpha10(prices): #49\n",
    "    cond = diff_ts(lagged_ts(prices, 10), 10).div(10).sub(diff_ts(prices, 10).div(10)) >= -0.1 * prices\n",
    "    return -diff_ts(prices, 1).where(cond, 1) \n",
    "\n",
    "\n",
    "def alpha11(prices): #51\n",
    "  cond = diff_ts(diff_ts(prices, 10), 10).div(10).sub(diff_ts(prices, 10).div(10)) >= -0.05 * prices\n",
    "  return -diff_ts(prices, 1).where(cond, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>return_1d</th>\n",
       "      <th>return_5d</th>\n",
       "      <th>return_21d</th>\n",
       "      <th>return_42d</th>\n",
       "      <th>return_63d</th>\n",
       "      <th>return_126d</th>\n",
       "      <th>return_189d</th>\n",
       "      <th>return_252d</th>\n",
       "      <th>momentum_2</th>\n",
       "      <th>momentum_3</th>\n",
       "      <th>momentum_6</th>\n",
       "      <th>momentum_9</th>\n",
       "      <th>momentum_12</th>\n",
       "      <th>momentum_3_12</th>\n",
       "      <th>r1_fwd</th>\n",
       "      <th>r5_fwd</th>\n",
       "      <th>r21_fwd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0.001486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1249</th>\n",
       "      <th>45</th>\n",
       "      <td>-0.006003</td>\n",
       "      <td>-0.009890</td>\n",
       "      <td>-0.016450</td>\n",
       "      <td>-0.026018</td>\n",
       "      <td>-0.021813</td>\n",
       "      <td>-0.040348</td>\n",
       "      <td>-0.038633</td>\n",
       "      <td>-0.029312</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>-0.005364</td>\n",
       "      <td>-0.023898</td>\n",
       "      <td>-0.022184</td>\n",
       "      <td>-0.012863</td>\n",
       "      <td>-0.007499</td>\n",
       "      <td>-0.006398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.006398</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.014370</td>\n",
       "      <td>0.102357</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>-0.005380</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.101583</td>\n",
       "      <td>0.077699</td>\n",
       "      <td>-0.006153</td>\n",
       "      <td>-0.019749</td>\n",
       "      <td>-0.005321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.005321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.045804</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>-0.079126</td>\n",
       "      <td>-0.115089</td>\n",
       "      <td>0.031218</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.011568</td>\n",
       "      <td>-0.093712</td>\n",
       "      <td>-0.129675</td>\n",
       "      <td>-0.127271</td>\n",
       "      <td>-0.007388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.007388</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>-0.037134</td>\n",
       "      <td>-0.024261</td>\n",
       "      <td>-0.069416</td>\n",
       "      <td>-0.042281</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>0.288298</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>-0.032282</td>\n",
       "      <td>-0.005147</td>\n",
       "      <td>0.186434</td>\n",
       "      <td>0.325432</td>\n",
       "      <td>0.357714</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>0.045674</td>\n",
       "      <td>0.048399</td>\n",
       "      <td>0.030935</td>\n",
       "      <td>0.026052</td>\n",
       "      <td>0.062241</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.032709</td>\n",
       "      <td>0.015246</td>\n",
       "      <td>0.010362</td>\n",
       "      <td>0.046551</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62450 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         return_1d  return_5d  return_21d  return_42d  return_63d  \\\n",
       "1    0    0.001486        NaN         NaN         NaN         NaN   \n",
       "     1    0.006281        NaN         NaN         NaN         NaN   \n",
       "     2    0.001238        NaN         NaN         NaN         NaN   \n",
       "     3   -0.000396        NaN         NaN         NaN         NaN   \n",
       "     4   -0.000768        NaN         NaN         NaN         NaN   \n",
       "...            ...        ...         ...         ...         ...   \n",
       "1249 45  -0.006003  -0.009890   -0.016450   -0.026018   -0.021813   \n",
       "     46  -0.006398   0.013443    0.000773    0.010541    0.014370   \n",
       "     47  -0.005321   0.000000    0.014586    0.045804    0.012183   \n",
       "     48  -0.007388   0.003565   -0.037134   -0.024261   -0.069416   \n",
       "     49   0.001957   0.004280    0.015690    0.045674    0.048399   \n",
       "\n",
       "         return_126d  return_189d  return_252d  momentum_2  momentum_3  \\\n",
       "1    0           NaN          NaN          NaN         NaN         NaN   \n",
       "     1           NaN          NaN          NaN         NaN         NaN   \n",
       "     2           NaN          NaN          NaN         NaN         NaN   \n",
       "     3           NaN          NaN          NaN         NaN         NaN   \n",
       "     4           NaN          NaN          NaN         NaN         NaN   \n",
       "...              ...          ...          ...         ...         ...   \n",
       "1249 45    -0.040348    -0.038633    -0.029312   -0.009568   -0.005364   \n",
       "     46     0.102357     0.078472    -0.005380    0.009768    0.013596   \n",
       "     47     0.003018    -0.079126    -0.115089    0.031218   -0.002403   \n",
       "     48    -0.042281     0.149300     0.288298    0.012872   -0.032282   \n",
       "     49     0.030935     0.026052     0.062241    0.029984    0.032709   \n",
       "\n",
       "         momentum_6  momentum_9  momentum_12  momentum_3_12    r1_fwd  r5_fwd  \\\n",
       "1    0          NaN         NaN          NaN            NaN  0.006281     NaN   \n",
       "     1          NaN         NaN          NaN            NaN  0.001238     NaN   \n",
       "     2          NaN         NaN          NaN            NaN -0.000396     NaN   \n",
       "     3          NaN         NaN          NaN            NaN -0.000768     NaN   \n",
       "     4          NaN         NaN          NaN            NaN -0.003846     NaN   \n",
       "...             ...         ...          ...            ...       ...     ...   \n",
       "1249 45   -0.023898   -0.022184    -0.012863      -0.007499 -0.006398     NaN   \n",
       "     46    0.101583    0.077699    -0.006153      -0.019749 -0.005321     NaN   \n",
       "     47   -0.011568   -0.093712    -0.129675      -0.127271 -0.007388     NaN   \n",
       "     48   -0.005147    0.186434     0.325432       0.357714  0.001957     NaN   \n",
       "     49    0.015246    0.010362     0.046551       0.013842       NaN     NaN   \n",
       "\n",
       "         r21_fwd  \n",
       "1    0       NaN  \n",
       "     1       NaN  \n",
       "     2       NaN  \n",
       "     3       NaN  \n",
       "     4       NaN  \n",
       "...          ...  \n",
       "1249 45      NaN  \n",
       "     46      NaN  \n",
       "     47      NaN  \n",
       "     48      NaN  \n",
       "     49      NaN  \n",
       "\n",
       "[62450 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = momentum_features(prcHistT)\n",
    "\n",
    "\n",
    "returns = (data[\"return_1d\"].unstack()).copy()\n",
    "\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already defined all the alpha functions\n",
    "\n",
    "# Calculate all alphas\n",
    "alpha1_result = alpha1(prcHistT, returns)\n",
    "alpha2_result = alpha2(prcHistT)\n",
    "alpha3_result = alpha3(prcHistT)\n",
    "alpha4_result = alpha4(prcHistT)\n",
    "alpha5_result = alpha5(prcHistT)\n",
    "alpha6_result = alpha6(prcHistT)\n",
    "alpha7_result = alpha7(prcHistT, returns)\n",
    "alpha8_result = alpha8(prcHistT, returns)\n",
    "alpha9_result = alpha9(prcHistT)\n",
    "alpha10_result = alpha10(prcHistT)\n",
    "alpha11_result = alpha11(prcHistT)\n",
    "\n",
    "# Combine all alphas into a single DataFrame\n",
    "all_alphas = pd.concat([\n",
    "    alpha1_result, alpha2_result, alpha3_result, alpha4_result,\n",
    "    alpha5_result, alpha6_result, alpha7_result, alpha8_result,\n",
    "    alpha9_result, alpha10_result, alpha11_result\n",
    "], axis=1, keys=['alpha1', 'alpha2', 'alpha3', 'alpha4', 'alpha5', \n",
    "                 'alpha6', 'alpha7', 'alpha8', 'alpha9', 'alpha10', 'alpha11'])\n",
    "\n",
    "# Reshape to match the MultiIndex structure\n",
    "all_alphas_stacked = all_alphas.stack()\n",
    "\n",
    "# Create MultiIndex\n",
    "time_index = range(len(prcHistT))\n",
    "stock_index = prcHistT.columns\n",
    "multi_index = pd.MultiIndex.from_product([time_index, stock_index], names=['time', 'stock'])\n",
    "\n",
    "# Reindex to ensure all combinations are present\n",
    "all_alphas_multi = all_alphas_stacked.reindex(multi_index)\n",
    "\n",
    "# Optionally, you can add other features from your previous DataFrame if needed\n",
    "# For example, if you want to include the return features:\n",
    "return_features = data[\n",
    "    [\"return_1d\", \"return_5d\", \"return_21d\", \"return_42d\", \"return_63d\", \"return_126d\", \"return_189d\", \"return_252d\",\n",
    "     \"momentum_2\", \"momentum_3\", \"momentum_6\", \"momentum_9\", \"momentum_12\", \"momentum_3_12\",\n",
    "     \"r1_fwd\", \"r5_fwd\", \"r21_fwd\"\n",
    "    ]\n",
    "]\n",
    "all_features = pd.concat([all_alphas_multi, return_features], axis=1)\n",
    "\n",
    "# Sort the index to ensure it's in the correct order\n",
    "all_features = all_features.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>alpha1</th>\n",
       "      <th>alpha2</th>\n",
       "      <th>alpha3</th>\n",
       "      <th>alpha4</th>\n",
       "      <th>alpha5</th>\n",
       "      <th>alpha6</th>\n",
       "      <th>alpha7</th>\n",
       "      <th>alpha8</th>\n",
       "      <th>alpha9</th>\n",
       "      <th>alpha10</th>\n",
       "      <th>...</th>\n",
       "      <th>return_252d</th>\n",
       "      <th>momentum_2</th>\n",
       "      <th>momentum_3</th>\n",
       "      <th>momentum_6</th>\n",
       "      <th>momentum_9</th>\n",
       "      <th>momentum_12</th>\n",
       "      <th>momentum_3_12</th>\n",
       "      <th>r1_fwd</th>\n",
       "      <th>r5_fwd</th>\n",
       "      <th>r21_fwd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1249</th>\n",
       "      <th>45</th>\n",
       "      <td>-0.150</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029312</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>-0.005364</td>\n",
       "      <td>-0.023898</td>\n",
       "      <td>-0.022184</td>\n",
       "      <td>-0.012863</td>\n",
       "      <td>-0.007499</td>\n",
       "      <td>-0.006398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.335</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005380</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.101583</td>\n",
       "      <td>0.077699</td>\n",
       "      <td>-0.006153</td>\n",
       "      <td>-0.019749</td>\n",
       "      <td>-0.005321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.255</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>5.14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115089</td>\n",
       "      <td>0.031218</td>\n",
       "      <td>-0.002403</td>\n",
       "      <td>-0.011568</td>\n",
       "      <td>-0.093712</td>\n",
       "      <td>-0.129675</td>\n",
       "      <td>-0.127271</td>\n",
       "      <td>-0.007388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.150</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288298</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>-0.032282</td>\n",
       "      <td>-0.005147</td>\n",
       "      <td>0.186434</td>\n",
       "      <td>0.325432</td>\n",
       "      <td>0.357714</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.150</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-3.31</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062241</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.032709</td>\n",
       "      <td>0.015246</td>\n",
       "      <td>0.010362</td>\n",
       "      <td>0.046551</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62500 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         alpha1  alpha2  alpha3  alpha4  alpha5  alpha6  alpha7  alpha8  \\\n",
       "0    0      NaN     NaN     NaN     NaN    0.00     NaN     NaN     NaN   \n",
       "     1      NaN     NaN     NaN     NaN    0.00     NaN     NaN     NaN   \n",
       "     2      NaN     NaN     NaN     NaN    0.00     NaN     NaN     NaN   \n",
       "     3      NaN     NaN     NaN     NaN    0.00     NaN     NaN     NaN   \n",
       "     4      NaN     NaN     NaN     NaN    0.00     NaN     NaN     NaN   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "1249 45  -0.150    -1.5    0.26    0.26    0.00   -0.00    3.69    0.34   \n",
       "     46  -0.335    -5.0    0.50    0.50    0.02   -0.65    3.02    0.64   \n",
       "     47  -0.255    -5.0    0.16    0.16    0.16   -1.31    5.14    0.75   \n",
       "     48  -0.150    -2.0    0.44    0.44    0.00    0.39    5.08    0.93   \n",
       "     49  -0.150    -8.0   -0.11   -0.11   -0.09   -3.31    4.34    0.20   \n",
       "\n",
       "         alpha9  alpha10  ...  return_252d  momentum_2  momentum_3  \\\n",
       "0    0      NaN    -1.00  ...          NaN         NaN         NaN   \n",
       "     1      NaN    -1.00  ...          NaN         NaN         NaN   \n",
       "     2      NaN    -1.00  ...          NaN         NaN         NaN   \n",
       "     3      NaN    -1.00  ...          NaN         NaN         NaN   \n",
       "     4      NaN    -1.00  ...          NaN         NaN         NaN   \n",
       "...         ...      ...  ...          ...         ...         ...   \n",
       "1249 45   -0.26     0.26  ...    -0.029312   -0.009568   -0.005364   \n",
       "     46    1.00     0.50  ...    -0.005380    0.009768    0.013596   \n",
       "     47   -0.16     0.16  ...    -0.115089    0.031218   -0.002403   \n",
       "     48    1.00     0.44  ...     0.288298    0.012872   -0.032282   \n",
       "     49    0.11    -0.11  ...     0.062241    0.029984    0.032709   \n",
       "\n",
       "         momentum_6  momentum_9  momentum_12  momentum_3_12    r1_fwd  r5_fwd  \\\n",
       "0    0          NaN         NaN          NaN            NaN       NaN     NaN   \n",
       "     1          NaN         NaN          NaN            NaN       NaN     NaN   \n",
       "     2          NaN         NaN          NaN            NaN       NaN     NaN   \n",
       "     3          NaN         NaN          NaN            NaN       NaN     NaN   \n",
       "     4          NaN         NaN          NaN            NaN       NaN     NaN   \n",
       "...             ...         ...          ...            ...       ...     ...   \n",
       "1249 45   -0.023898   -0.022184    -0.012863      -0.007499 -0.006398     NaN   \n",
       "     46    0.101583    0.077699    -0.006153      -0.019749 -0.005321     NaN   \n",
       "     47   -0.011568   -0.093712    -0.129675      -0.127271 -0.007388     NaN   \n",
       "     48   -0.005147    0.186434     0.325432       0.357714  0.001957     NaN   \n",
       "     49    0.015246    0.010362     0.046551       0.013842       NaN     NaN   \n",
       "\n",
       "         r21_fwd  \n",
       "0    0       NaN  \n",
       "     1       NaN  \n",
       "     2       NaN  \n",
       "     3       NaN  \n",
       "     4       NaN  \n",
       "...          ...  \n",
       "1249 45      NaN  \n",
       "     46      NaN  \n",
       "     47      NaN  \n",
       "     48      NaN  \n",
       "     49      NaN  \n",
       "\n",
       "[62500 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fi(model):\n",
    "  fi = model.feature_importance(importance_type=\"gain\")\n",
    "  return pd.Series(fi / fi.sum(), index=model.feature_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Parameters: 108\n",
      "['r1_fwd', 'r21_fwd', 'r5_fwd']\n",
      "['alpha1', 'alpha10', 'alpha11', 'alpha2', 'alpha3', 'alpha4', 'alpha5', 'alpha6', 'alpha7', 'alpha8', 'alpha9', 'momentum_12', 'momentum_2', 'momentum_3', 'momentum_3_12', 'momentum_6', 'momentum_9', 'return_126d', 'return_189d', 'return_1d', 'return_21d', 'return_252d', 'return_42d', 'return_5d', 'return_63d']\n",
      "Train configs: 6\n"
     ]
    }
   ],
   "source": [
    "base_params = dict(boosting='gbdt', objective='regression', verbose=-1)\n",
    "\n",
    "max_depths = [2, 3, 5, 7]\n",
    "num_leaves_opts = [2**i for i in max_depths]\n",
    "min_data_in_leaf_opts = [250, 500, 1000]\n",
    "\n",
    "learning_rate_ops = [0.01, 0.1, 0.3]\n",
    "feature_fraction_opts = [0.3, 0.6, 0.95]\n",
    "\n",
    "param_names = [\"learning_rate\", \"num_leaves\", \"feature_fraction\", \"min_data_in_leaf\"]\n",
    "\n",
    "cv_params = list(product(learning_rate_ops, num_leaves_opts, feature_fraction_opts, min_data_in_leaf_opts))\n",
    "n_params = len(cv_params)\n",
    "print(f\"# Parameters: {n_params}\")\n",
    "\n",
    "\n",
    "labels = sorted(data.filter(like=\"_fwd\").columns)\n",
    "print(labels)\n",
    "features = all_features.columns.difference(labels).tolist()\n",
    "print(features)\n",
    "lookaheads = [1, 5, 21]  # 1 day, 1 week, 1 month\n",
    "label_dict = dict(zip(lookaheads, labels))\n",
    "\n",
    "train_lengths = [(3 * 252), 126]\n",
    "test_lengths = [63]\n",
    "test_params = list(product(lookaheads, train_lengths, test_lengths))\n",
    "n = len(test_params)\n",
    "test_param_sample = np.random.choice(list(range(n)), size=int(n), replace=False)\n",
    "test_params = [test_params[i] for i in test_param_sample]\n",
    "print(\"Train configs:\", len(test_params))\n",
    "\n",
    "\n",
    "def ic_lgbm(preds, train_data):\n",
    "    is_higher_better = True\n",
    "    return \"ic\", spearmanr(preds, train_data.get_label())[0], is_higher_better\n",
    "\n",
    "\n",
    "num_iterations = [10, 25, 50, 75] + list(range(100, 501, 50))\n",
    "num_boost_round = num_iterations[-1]\n",
    "\n",
    "metric_cols = (\n",
    "    param_names\n",
    "    + [\"t\", \"daily_ic_mean\", \"daily_ic_mean_n\", \"daily_ic_median\", \"daily_ic_median_n\"]\n",
    "    + [str(n) for n in num_iterations]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookahead:  1 | Train: 756 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:12 ( 12) |  0.10 | 128 | 60% |  250 |  11.85% |  10.61% |  450 |  10.39% |  100\n",
      "\t  1 | 00:00:19 (  7) |  0.01 |  32 | 60% |  500 |   3.68% |  0.17% |  350 |  4.34% |  350\n",
      "\t  2 | 00:00:25 (  6) |  0.10 |  32 | 95% | 1000 |   2.84% |  0.31% |  350 |  6.36% |  300\n",
      "\t  3 | 00:00:28 (  3) |  0.10 |   8 | 95% |  500 |   6.11% |  1.57% |   50 |  3.73% |   50\n",
      "\t  4 | 00:00:31 (  2) |  0.01 |   8 | 30% |  500 |   3.73% |  0.55% |   25 |  2.06% |  400\n",
      "\t  5 | 00:00:33 (  3) |  0.10 |   8 | 60% |  250 |   5.83% |  2.61% |  400 |  7.64% |  300\n",
      "\t  6 | 00:00:36 (  2) |  0.01 |   4 | 95% |  500 |   1.85% | -1.18% |  350 |  0.78% |   75\n",
      "\t  7 | 00:00:39 (  3) |  0.01 |   8 | 95% |  500 |   5.15% |  1.39% |  500 |  2.62% |   25\n",
      "\t  8 | 00:00:47 (  8) |  0.30 |  32 | 95% |  500 |   5.11% |  6.16% |  250 |  4.39% |  400\n",
      "\t  9 | 00:00:50 (  3) |  0.30 |   8 | 60% | 1000 |   4.05% |  0.65% |   10 |  1.59% |  300\n",
      "\t 10 | 00:00:53 (  3) |  0.01 |   8 | 60% | 1000 |   6.19% |  3.35% |   25 |  3.36% |   25\n",
      "\t 11 | 00:01:00 (  7) |  0.01 |  32 | 30% |  250 |   5.25% |  1.65% |   25 |  6.83% |  500\n",
      "\t 12 | 00:01:04 (  4) |  0.30 |   8 | 95% |  500 |   2.23% | -0.51% |  100 |  1.48% |  100\n",
      "\t 13 | 00:01:12 (  8) |  0.01 | 128 | 30% |  500 |   1.74% |  0.96% |   10 |  4.01% |   10\n",
      "\t 14 | 00:01:17 (  5) |  0.10 |  32 | 60% | 1000 |   3.71% | -0.70% |   25 |  0.30% |   50\n",
      "\t 15 | 00:01:20 (  3) |  0.01 |   8 | 30% |  250 |   4.92% |  1.28% |   10 |  2.27% |  450\n",
      "\t 16 | 00:01:37 ( 17) |  0.01 | 128 | 95% |  250 |   3.49% |  2.63% |  500 |  2.98% |  400\n",
      "\t 17 | 00:01:40 (  3) |  0.10 |   8 | 60% |  500 |   4.83% |  2.38% |  100 |  4.92% |  100\n",
      "\t 18 | 00:01:42 (  3) |  0.30 |   4 | 95% |  250 |   4.00% |  3.01% |   25 |  9.68% |  350\n",
      "\t 19 | 00:01:45 (  3) |  0.30 |   4 | 95% |  500 |   3.25% |  1.47% |   75 |  5.75% |  300\n",
      "\t 20 | 00:01:48 (  3) |  0.30 |   4 | 60% | 1000 |   1.34% | -2.98% |   25 |  4.37% |  200\n",
      "\t 21 | 00:02:01 ( 13) |  0.30 | 128 | 30% |  250 |   9.76% |  8.88% |   10 |  8.07% |   25\n",
      "\t 22 | 00:02:04 (  3) |  0.10 |   8 | 30% |  500 |   1.57% | -0.75% |   25 |  0.86% |   75\n",
      "\t 23 | 00:02:09 (  5) |  0.01 | 128 | 60% | 1000 |   3.61% | -1.19% |   25 |  0.41% |  400\n",
      "\t 24 | 00:02:11 (  3) |  0.01 |   4 | 95% | 1000 |   6.17% |  2.92% |  500 |  3.87% |  150\n",
      "\t 25 | 00:02:18 (  7) |  0.10 | 128 | 95% | 1000 |   2.84% |  0.31% |  350 |  6.36% |  300\n",
      "\t 26 | 00:02:27 (  9) |  0.10 |  32 | 95% |  500 |   4.72% |  4.65% |  500 |  4.24% |  200\n",
      "\t 27 | 00:02:30 (  3) |  0.30 |   8 | 30% |  500 |   4.05% |  1.81% |   50 |  7.09% |   50\n",
      "\t 28 | 00:02:33 (  3) |  0.01 |   8 | 60% |  250 |   6.07% |  3.16% |   25 |  3.10% |   25\n",
      "\t 29 | 00:02:35 (  2) |  0.01 |   4 | 30% |  500 |   3.75% |  3.72% |   50 |  1.50% |  500\n",
      "\t 30 | 00:02:39 (  3) |  0.30 |   8 | 95% |  250 |   8.72% |  8.02% |   50 |  15.27% |   50\n",
      "\t 31 | 00:02:45 (  6) |  0.30 |  32 | 30% | 1000 |   2.57% |  1.04% |  450 |  1.24% |  450\n",
      "\t 32 | 00:02:51 (  7) |  0.10 |  32 | 60% |  500 |   5.76% |  3.41% |  450 |  8.35% |   75\n",
      "\t 33 | 00:03:02 ( 11) |  0.10 | 128 | 95% |  500 |   5.63% |  4.82% |  500 |  7.27% |  150\n",
      "\t 34 | 00:03:04 (  2) |  0.30 |   4 | 30% |  250 |   2.01% |  0.99% |   25 |  3.72% |  250\n",
      "\t 35 | 00:03:12 (  8) |  0.30 |  32 | 60% |  250 |   6.94% |  6.77% |   25 |  11.14% |   10\n",
      "\t 36 | 00:03:20 (  8) |  0.01 |  32 | 60% |  250 |   3.82% | -0.15% |  450 |  1.01% |  450\n",
      "\t 37 | 00:03:32 ( 13) |  0.01 | 128 | 30% |  250 |   4.68% |  1.05% |  350 |  6.96% |  350\n",
      "\t 38 | 00:03:35 (  2) |  0.01 |   4 | 60% |  500 |   3.33% |  0.36% |  250 |  0.45% |   50\n",
      "\t 39 | 00:03:37 (  2) |  0.30 |   4 | 60% |  500 |   1.49% | -2.78% |   25 |  4.80% |  100\n",
      "\t 40 | 00:03:50 ( 14) |  0.10 | 128 | 30% |  250 |   4.50% |  3.57% |  450 |  4.63% |   75\n",
      "\t 41 | 00:03:53 (  2) |  0.01 |   4 | 30% | 1000 |   4.75% |  3.31% |   50 |  6.99% |   50\n",
      "\t 42 | 00:03:59 (  6) |  0.01 |  32 | 95% | 1000 |   4.15% | -1.34% |  300 |  0.44% |   10\n",
      "\t 43 | 00:04:08 (  9) |  0.01 |  32 | 95% |  500 |   3.49% |  1.28% |  450 |  2.56% |  450\n",
      "\t 44 | 00:04:16 (  8) |  0.30 | 128 | 60% |  500 |   7.31% |  5.95% |  400 |  9.04% |  450\n",
      "\t 45 | 00:04:21 (  5) |  0.10 |  32 | 30% | 1000 |   4.56% |  2.68% |   10 |  2.20% |   10\n",
      "\t 46 | 00:04:23 (  2) |  0.10 |   4 | 30% | 1000 |   4.37% |  0.04% |   75 |  3.18% |   75\n",
      "\t 47 | 00:04:30 (  7) |  0.01 |  32 | 95% |  250 |   5.61% |  3.99% |  350 |  6.70% |  400\n",
      "\t 48 | 00:04:34 (  4) |  0.10 |   8 | 95% | 1000 |   4.29% | -1.38% |  200 |  3.43% |   75\n",
      "\t 49 | 00:04:41 (  7) |  0.10 |  32 | 30% |  500 |   5.28% |  1.64% |   25 |  5.21% |   10\n",
      "\t 50 | 00:04:44 (  3) |  0.10 |   4 | 95% |  250 |   4.22% |  0.43% |  100 |  0.44% |  300\n",
      "\t 51 | 00:04:47 (  3) |  0.10 |   8 | 30% |  250 |   6.95% |  4.09% |  200 |  5.37% |  300\n",
      "\t 52 | 00:04:58 ( 10) |  0.30 |  32 | 30% |  500 |   9.13% |  9.99% |   50 |  11.64% |  500\n",
      "\t 53 | 00:05:07 ( 10) |  0.01 | 128 | 60% |  500 |   5.39% |  1.35% |  400 |  4.80% |  500\n",
      "Lookahead:  5 | Train: 756 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:03 (  3) |  0.30 |   8 | 30% |  500 |  23.01% |  25.42% |  450 |  28.35% |  250\n",
      "\t  1 | 00:00:05 (  2) |  0.10 |   4 | 60% |  500 |  14.71% |  16.95% |  450 |  13.65% |  450\n",
      "\t  2 | 00:00:20 ( 15) |  0.10 | 128 | 60% |  250 |  33.84% |  35.37% |  300 |  39.43% |  500\n",
      "\t  3 | 00:00:26 (  5) |  0.10 | 128 | 60% | 1000 |  22.38% |  23.29% |  350 |  33.18% |  450\n",
      "\t  4 | 00:00:31 (  5) |  0.10 | 128 | 30% | 1000 |  21.35% |  23.28% |  500 |  28.30% |  500\n",
      "\t  5 | 00:00:34 (  3) |  0.30 |   8 | 30% | 1000 |  22.37% |  25.07% |  400 |  30.64% |  300\n",
      "\t  6 | 00:00:40 (  6) |  0.01 | 128 | 30% | 1000 |  11.39% |  13.29% |  500 |  15.74% |  450\n",
      "\t  7 | 00:00:43 (  3) |  0.01 |   8 | 30% |  500 |   6.11% |  8.12% |  500 |  7.04% |  500\n",
      "\t  8 | 00:00:47 (  4) |  0.01 |   8 | 60% |  250 |   8.99% |  10.83% |  450 |  10.81% |  450\n",
      "\t  9 | 00:00:50 (  3) |  0.01 |   8 | 60% |  500 |   8.95% |  10.77% |  500 |  9.09% |  500\n",
      "\t 10 | 00:00:59 (  9) |  0.10 | 128 | 95% |  500 |  32.02% |  34.47% |  450 |  38.18% |  450\n",
      "\t 11 | 00:01:02 (  3) |  0.30 |   4 | 95% | 1000 |  16.79% |  18.26% |  350 |  20.32% |  500\n",
      "\t 12 | 00:01:04 (  3) |  0.01 |   4 | 60% | 1000 |   6.00% |  7.90% |  500 |  8.05% |  500\n",
      "\t 13 | 00:01:12 (  7) |  0.30 | 128 | 30% |  500 |  27.57% |  29.35% |  450 |  29.38% |  400\n",
      "\t 14 | 00:01:14 (  3) |  0.01 |   4 | 95% |  500 |   6.45% |  8.47% |  500 |  5.32% |  500\n",
      "\t 15 | 00:01:24 ( 10) |  0.10 |  32 | 30% |  250 |  29.17% |  30.00% |  500 |  32.66% |  500\n",
      "\t 16 | 00:01:26 (  3) |  0.01 |   4 | 30% |  500 |  -0.75% |  2.07% |  500 |  4.29% |  500\n",
      "\t 17 | 00:01:29 (  3) |  0.30 |   4 | 60% |  500 |  17.57% |  19.88% |  500 |  23.03% |  500\n",
      "\t 18 | 00:01:33 (  3) |  0.01 |   4 | 60% |  250 |   5.67% |  8.92% |  450 |  7.61% |  400\n",
      "\t 19 | 00:01:45 ( 12) |  0.01 |  32 | 60% |  500 |  21.53% |  24.33% |  500 |  19.06% |  500\n",
      "\t 20 | 00:02:04 ( 20) |  0.30 | 128 | 30% |  250 |  29.27% |  30.95% |  350 |  38.05% |   75\n",
      "\t 21 | 00:02:07 (  3) |  0.30 |   4 | 60% | 1000 |  14.02% |  15.66% |  500 |  22.04% |  350\n",
      "\t 22 | 00:02:11 (  4) |  0.10 |   8 | 30% |  250 |  20.77% |  22.46% |  400 |  22.44% |  300\n",
      "\t 23 | 00:02:23 ( 12) |  0.30 |  32 | 95% |  250 |  32.94% |  35.25% |  300 |  35.94% |  300\n",
      "\t 24 | 00:02:30 (  7) |  0.10 |  32 | 60% | 1000 |  22.38% |  23.29% |  350 |  33.18% |  450\n",
      "\t 25 | 00:02:40 ( 10) |  0.10 | 128 | 30% |  500 |  30.62% |  32.17% |  500 |  32.93% |  200\n",
      "\t 26 | 00:02:47 (  7) |  0.01 | 128 | 60% | 1000 |  16.49% |  18.98% |  500 |  19.26% |  500\n",
      "\t 27 | 00:02:52 (  5) |  0.01 |   8 | 30% |  250 |   7.51% |  9.52% |  500 |  10.57% |  500\n",
      "\t 28 | 00:02:56 (  4) |  0.10 |   4 | 60% | 1000 |  10.94% |  12.61% |  250 |  13.57% |  350\n",
      "\t 29 | 00:02:59 (  3) |  0.30 |   4 | 95% |  250 |  25.67% |  27.91% |  500 |  28.41% |  500\n",
      "\t 30 | 00:03:18 ( 19) |  0.01 |  32 | 95% |  250 |  24.78% |  26.56% |  450 |  23.28% |  450\n",
      "\t 31 | 00:03:20 (  3) |  0.30 |   4 | 30% |  250 |  16.88% |  19.89% |  500 |  20.62% |  500\n",
      "\t 32 | 00:03:35 ( 15) |  0.01 | 128 | 95% |  500 |  21.26% |  23.57% |  500 |  19.75% |  500\n",
      "\t 33 | 00:03:46 ( 11) |  0.30 |  32 | 30% |  500 |  31.40% |  30.09% |  450 |  28.47% |   50\n",
      "\t 34 | 00:03:49 (  4) |  0.01 |   8 | 60% | 1000 |  10.37% |  11.86% |  500 |  13.18% |  350\n",
      "\t 35 | 00:03:52 (  3) |  0.10 |   4 | 95% | 1000 |  11.12% |  14.41% |  450 |  13.92% |  450\n",
      "\t 36 | 00:03:56 (  3) |  0.01 |   8 | 30% | 1000 |   5.89% |  6.55% |  500 |  6.03% |  500\n",
      "\t 37 | 00:04:07 ( 11) |  0.01 |  32 | 95% |  500 |  21.10% |  23.46% |  450 |  21.06% |  450\n",
      "\t 38 | 00:04:11 (  4) |  0.10 |   8 | 60% |  500 |  19.00% |  21.21% |  500 |  17.39% |  350\n",
      "\t 39 | 00:04:13 (  2) |  0.10 |   4 | 30% |  250 |  16.07% |  18.74% |  450 |  15.37% |  350\n",
      "\t 40 | 00:04:18 (  5) |  0.30 |   8 | 95% |  500 |  25.58% |  25.55% |  300 |  27.82% |  500\n",
      "\t 41 | 00:04:29 ( 10) |  0.10 |  32 | 60% |  500 |  29.95% |  31.99% |  500 |  36.77% |  500\n",
      "\t 42 | 00:04:36 (  7) |  0.30 |  32 | 60% | 1000 |  26.29% |  30.04% |  500 |  28.82% |  200\n",
      "\t 43 | 00:04:39 (  3) |  0.10 |   4 | 95% |  500 |  12.60% |  14.85% |  350 |  10.32% |   75\n",
      "\t 44 | 00:04:49 ( 10) |  0.01 |  32 | 30% |  500 |  18.20% |  19.77% |  500 |  21.11% |  500\n",
      "\t 45 | 00:05:04 ( 15) |  0.01 | 128 | 60% |  250 |  28.39% |  30.40% |  500 |  30.25% |  500\n",
      "\t 46 | 00:05:19 ( 15) |  0.01 | 128 | 30% |  250 |  23.33% |  25.60% |  500 |  29.01% |  300\n",
      "\t 47 | 00:05:22 (  2) |  0.10 |   4 | 30% | 1000 |  12.83% |  14.76% |  400 |  21.01% |  500\n",
      "\t 48 | 00:05:32 ( 10) |  0.01 | 128 | 60% |  500 |  22.42% |  24.62% |  500 |  20.52% |  500\n",
      "\t 49 | 00:05:45 ( 13) |  0.30 |  32 | 95% |  500 |  33.36% |  34.68% |  300 |  33.60% |  250\n",
      "\t 50 | 00:05:48 (  3) |  0.10 |   4 | 30% |  500 |  14.45% |  16.71% |  500 |  12.81% |  250\n",
      "\t 51 | 00:05:52 (  4) |  0.10 |   8 | 60% |  250 |  21.45% |  23.54% |  500 |  21.28% |  450\n",
      "\t 52 | 00:05:58 (  6) |  0.10 |  32 | 30% | 1000 |  21.35% |  23.28% |  500 |  28.30% |  500\n",
      "\t 53 | 00:06:11 ( 13) |  0.10 |  32 | 95% |  250 |  31.29% |  32.33% |  300 |  35.57% |  450\n",
      "Lookahead:  5 | Train: 126 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:04 (  4) |  0.10 |   8 | 60% | 1000 |  17.76% |  21.37% |  500 |  26.95% |  500\n",
      "\t  1 | 00:00:13 (  9) |  0.01 | 128 | 95% | 1000 |  16.69% |  20.64% |  500 |  18.72% |  450\n",
      "\t  2 | 00:00:19 (  5) |  0.10 |   8 | 95% |  500 |  20.08% |  23.21% |  500 |  19.58% |  350\n",
      "\t  3 | 00:00:28 (  9) |  0.01 |  32 | 95% | 1000 |  16.69% |  20.64% |  500 |  18.72% |  450\n",
      "\t  4 | 00:00:31 (  3) |  0.01 |   4 | 95% |  500 |   6.45% |  8.47% |  500 |  5.32% |  500\n",
      "\t  5 | 00:00:36 (  5) |  0.10 |   8 | 60% |  500 |  19.00% |  21.21% |  500 |  17.39% |  350\n",
      "\t  6 | 00:00:39 (  3) |  0.30 |   4 | 30% |  250 |  16.88% |  19.89% |  500 |  20.62% |  500\n",
      "\t  7 | 00:00:42 (  3) |  0.01 |   4 | 30% |  250 |   0.90% |  4.01% |  500 |  5.07% |  500\n",
      "\t  8 | 00:00:44 (  3) |  0.10 |   4 | 30% |  250 |  16.07% |  18.74% |  450 |  15.37% |  350\n",
      "\t  9 | 00:00:48 (  4) |  0.01 |   8 | 60% |  500 |   8.95% |  10.77% |  500 |  9.09% |  500\n",
      "\t 10 | 00:00:51 (  3) |  0.01 |   4 | 95% |  250 |   6.87% |  9.96% |  500 |  8.15% |  450\n",
      "\t 11 | 00:01:11 ( 20) |  0.30 | 128 | 95% |  250 |  33.33% |  32.54% |  250 |  32.98% |  450\n",
      "\t 12 | 00:01:24 ( 13) |  0.10 | 128 | 95% |  500 |  32.02% |  34.47% |  450 |  38.18% |  450\n",
      "\t 13 | 00:01:27 (  3) |  0.10 |   4 | 60% | 1000 |  10.94% |  12.61% |  250 |  13.57% |  350\n",
      "\t 14 | 00:01:37 ( 10) |  0.01 | 128 | 30% |  500 |  18.11% |  19.11% |  500 |  20.62% |  450\n",
      "\t 15 | 00:01:45 (  8) |  0.30 | 128 | 95% | 1000 |  24.20% |  27.00% |  250 |  27.41% |  150\n",
      "\t 16 | 00:01:55 ( 10) |  0.30 | 128 | 60% |  500 |  31.02% |  32.54% |  350 |  33.10% |  500\n",
      "\t 17 | 00:02:06 ( 11) |  0.01 |  32 | 95% |  250 |  24.78% |  26.56% |  450 |  23.28% |  450\n",
      "\t 18 | 00:02:16 ( 10) |  0.01 |  32 | 60% |  250 |  24.73% |  26.28% |  500 |  25.39% |  500\n",
      "\t 19 | 00:02:25 (  9) |  0.10 |  32 | 30% |  500 |  26.29% |  30.23% |  250 |  34.29% |  350\n",
      "\t 20 | 00:02:27 (  2) |  0.01 |   4 | 30% | 1000 |  -1.33% |  0.55% |  500 |  4.63% |  500\n",
      "\t 21 | 00:02:30 (  3) |  0.01 |   4 | 60% | 1000 |   6.00% |  7.90% |  500 |  8.05% |  500\n",
      "\t 22 | 00:02:39 ( 10) |  0.10 | 128 | 60% |  500 |  29.46% |  30.93% |  200 |  34.01% |  150\n",
      "\t 23 | 00:02:48 (  9) |  0.30 |  32 | 30% |  250 |  29.92% |  30.95% |  350 |  33.28% |  300\n",
      "\t 24 | 00:03:09 ( 21) |  0.01 | 128 | 95% |  250 |  28.67% |  30.56% |  400 |  27.66% |  350\n",
      "\t 25 | 00:03:13 (  4) |  0.30 |   8 | 60% | 1000 |  22.52% |  24.95% |  500 |  30.34% |  500\n",
      "\t 26 | 00:03:26 ( 13) |  0.01 | 128 | 95% |  500 |  21.26% |  23.57% |  500 |  19.75% |  500\n",
      "\t 27 | 00:03:41 ( 14) |  0.01 | 128 | 30% |  250 |  23.33% |  25.60% |  500 |  29.01% |  300\n",
      "\t 28 | 00:03:43 (  2) |  0.30 |   4 | 30% | 1000 |  15.67% |  16.64% |  450 |  19.01% |  300\n",
      "\t 29 | 00:03:47 (  4) |  0.30 |   8 | 30% | 1000 |  22.37% |  25.07% |  400 |  30.64% |  300\n",
      "\t 30 | 00:03:49 (  3) |  0.10 |   4 | 30% | 1000 |  12.83% |  14.76% |  400 |  21.01% |  500\n",
      "\t 31 | 00:03:52 (  3) |  0.01 |   4 | 60% |  250 |   5.67% |  8.92% |  450 |  7.61% |  400\n",
      "\t 32 | 00:03:55 (  3) |  0.10 |   4 | 95% |  500 |  12.60% |  14.85% |  350 |  10.32% |   75\n",
      "\t 33 | 00:03:58 (  3) |  0.10 |   4 | 60% |  500 |  14.71% |  16.95% |  450 |  13.65% |  450\n",
      "\t 34 | 00:04:10 ( 12) |  0.01 |  32 | 30% |  500 |  18.20% |  19.77% |  500 |  21.11% |  500\n",
      "\t 35 | 00:04:13 (  4) |  0.30 |   8 | 30% |  500 |  23.01% |  25.42% |  450 |  28.35% |  250\n",
      "\t 36 | 00:04:20 (  7) |  0.10 | 128 | 60% | 1000 |  22.38% |  23.29% |  350 |  33.18% |  450\n",
      "\t 37 | 00:04:25 (  5) |  0.10 |   8 | 95% |  250 |  20.29% |  22.62% |  450 |  19.51% |  450\n",
      "\t 38 | 00:04:35 ( 10) |  0.01 |  32 | 30% |  250 |  20.63% |  22.34% |  500 |  23.87% |  500\n",
      "\t 39 | 00:04:43 (  9) |  0.10 |  32 | 95% | 1000 |  24.07% |  26.53% |  500 |  28.00% |  500\n",
      "\t 40 | 00:04:52 (  9) |  0.30 |  32 | 30% |  500 |  31.40% |  30.09% |  450 |  28.47% |   50\n",
      "\t 41 | 00:04:55 (  3) |  0.30 |   4 | 60% |  500 |  17.57% |  19.88% |  500 |  23.03% |  500\n",
      "\t 42 | 00:05:02 (  8) |  0.01 | 128 | 60% | 1000 |  16.49% |  18.98% |  500 |  19.26% |  500\n",
      "\t 43 | 00:05:06 (  4) |  0.10 |   8 | 60% |  250 |  21.45% |  23.54% |  500 |  21.28% |  450\n",
      "\t 44 | 00:05:12 (  6) |  0.01 |  32 | 30% | 1000 |  11.39% |  13.29% |  500 |  15.74% |  450\n",
      "\t 45 | 00:05:16 (  4) |  0.10 |   8 | 30% |  250 |  20.77% |  22.46% |  400 |  22.44% |  300\n",
      "\t 46 | 00:05:19 (  3) |  0.10 |   4 | 95% |  250 |  11.78% |  14.00% |  450 |  9.98% |   75\n",
      "\t 47 | 00:05:23 (  4) |  0.10 |   8 | 30% |  500 |  22.14% |  24.91% |  450 |  24.88% |  500\n",
      "\t 48 | 00:05:25 (  3) |  0.01 |   4 | 60% |  500 |   4.41% |  7.10% |  500 |  6.28% |  500\n",
      "\t 49 | 00:05:37 ( 11) |  0.30 |  32 | 95% |  500 |  33.36% |  34.68% |  300 |  33.60% |  250\n",
      "\t 50 | 00:05:48 ( 11) |  0.10 |  32 | 30% |  250 |  29.17% |  30.00% |  500 |  32.66% |  500\n",
      "\t 51 | 00:05:58 ( 10) |  0.30 | 128 | 30% |  500 |  27.57% |  29.35% |  450 |  29.38% |  400\n",
      "\t 52 | 00:06:01 (  3) |  0.10 |   4 | 60% |  250 |  12.24% |  14.75% |  500 |  12.12% |  400\n",
      "\t 53 | 00:06:06 (  6) |  0.01 |   8 | 95% |  500 |   8.59% |  9.97% |  500 |  4.43% |  500\n",
      "Lookahead: 21 | Train: 126 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:13 ( 13) |  0.30 |  32 | 95% |  250 |  24.95% |  20.55% |  450 |  22.98% |  350\n",
      "\t  1 | 00:00:17 (  4) |  0.30 |   8 | 60% |  250 |  10.20% |  5.07% |  150 |  6.23% |  400\n",
      "\t  2 | 00:00:24 (  7) |  0.30 | 128 | 60% | 1000 |  20.92% |  14.44% |  400 |  18.95% |  450\n",
      "\t  3 | 00:00:27 (  3) |  0.01 |   4 | 60% |  250 |   5.56% |  3.43% |  250 |  4.90% |  500\n",
      "\t  4 | 00:00:34 (  8) |  0.01 |  32 | 95% | 1000 |   8.28% |  3.00% |  450 |  3.02% |  350\n",
      "\t  5 | 00:00:49 ( 14) |  0.01 | 128 | 30% |  250 |  15.91% |  9.00% |  500 |  8.35% |  500\n",
      "\t  6 | 00:01:07 ( 18) |  0.10 | 128 | 30% |  250 |  18.25% |  13.27% |  500 |  20.44% |  500\n",
      "\t  7 | 00:01:15 (  9) |  0.10 |  32 | 30% |  250 |  13.14% |  7.07% |   10 |  7.56% |  350\n",
      "\t  8 | 00:01:18 (  2) |  0.30 |   4 | 30% |  250 |  10.33% |  8.60% |   50 |  9.78% |   50\n",
      "\t  9 | 00:01:25 (  8) |  0.30 |  32 | 95% | 1000 |  17.98% |  12.21% |  500 |  16.72% |  500\n",
      "\t 10 | 00:01:32 (  6) |  0.01 | 128 | 60% | 1000 |  10.12% |  7.22% |  500 |  6.16% |  300\n",
      "\t 11 | 00:01:41 (  9) |  0.30 |  32 | 30% |  250 |  15.67% |  11.79% |  500 |  16.65% |  250\n",
      "\t 12 | 00:01:51 ( 11) |  0.01 | 128 | 30% |  500 |  13.49% |  7.33% |  500 |  4.53% |  100\n",
      "\t 13 | 00:01:56 (  4) |  0.01 |   8 | 60% |  500 |   6.82% |  4.13% |   25 |  4.31% |   25\n",
      "\t 14 | 00:02:12 ( 16) |  0.01 | 128 | 60% |  250 |  15.46% |  10.53% |  200 |  10.42% |  200\n",
      "\t 15 | 00:02:15 (  3) |  0.30 |   4 | 95% |  250 |  10.54% |  8.21% |   75 |  11.24% |  300\n",
      "\t 16 | 00:02:25 ( 10) |  0.01 |  32 | 30% |  500 |  14.12% |  7.60% |  500 |  3.93% |  100\n",
      "\t 17 | 00:02:30 (  5) |  0.30 |   8 | 95% | 1000 |  12.49% |  7.70% |  200 |  13.74% |  500\n",
      "\t 18 | 00:02:33 (  3) |  0.10 |   4 | 30% |  250 |   7.51% |  4.39% |  150 |  9.98% |  200\n",
      "\t 19 | 00:02:35 (  2) |  0.01 |   4 | 30% |  500 |   5.79% |  4.31% |  500 |  6.53% |   75\n",
      "\t 20 | 00:02:39 (  4) |  0.01 |   8 | 30% | 1000 |   5.75% |  4.31% |   75 |  3.67% |  200\n",
      "\t 21 | 00:02:52 ( 13) |  0.10 | 128 | 95% |  500 |  18.58% |  11.84% |  500 |  19.14% |  500\n",
      "\t 22 | 00:03:03 ( 11) |  0.10 | 128 | 60% |  500 |  19.81% |  14.10% |  500 |  17.34% |  300\n",
      "\t 23 | 00:03:16 ( 13) |  0.01 |  32 | 95% |  250 |  11.44% |  6.23% |   25 |  6.38% |   25\n",
      "\t 24 | 00:03:27 ( 11) |  0.10 |  32 | 95% |  250 |  18.79% |  13.00% |  400 |  12.88% |  500\n",
      "\t 25 | 00:03:30 (  3) |  0.10 |   4 | 95% |  250 |   9.07% |  5.34% |  300 |  8.82% |  350\n",
      "\t 26 | 00:03:36 (  6) |  0.01 |   8 | 95% | 1000 |   6.43% |  1.96% |  350 |  1.19% |  300\n",
      "\t 27 | 00:03:41 (  5) |  0.01 |   8 | 95% |  500 |   5.80% |  3.95% |  500 |  3.09% |  400\n",
      "\t 28 | 00:03:45 (  4) |  0.10 |   8 | 60% |  250 |  12.50% |  8.62% |  500 |  7.83% |  500\n",
      "\t 29 | 00:03:47 (  2) |  0.10 |   4 | 30% |  500 |   8.91% |  7.72% |  400 |  9.83% |  500\n",
      "\t 30 | 00:03:50 (  4) |  0.10 |   4 | 95% | 1000 |   9.27% |  5.61% |   75 |  8.18% |  100\n",
      "\t 31 | 00:03:53 (  2) |  0.10 |   4 | 30% | 1000 |   8.23% |  4.79% |  150 |  4.29% |  450\n",
      "\t 32 | 00:04:05 ( 12) |  0.10 |  32 | 30% |  500 |  14.88% |  7.81% |  500 |  10.42% |  100\n",
      "\t 33 | 00:04:10 (  5) |  0.30 |   8 | 60% | 1000 |  15.46% |  10.68% |   50 |  13.75% |  450\n",
      "\t 34 | 00:04:13 (  3) |  0.10 |   4 | 95% |  500 |  10.76% |  8.01% |  300 |  7.81% |  300\n",
      "\t 35 | 00:04:23 ( 10) |  0.10 |  32 | 60% |  250 |  19.24% |  13.97% |  350 |  16.95% |  300\n",
      "\t 36 | 00:04:25 (  3) |  0.30 |   4 | 60% |  500 |  12.92% |  7.15% |  400 |  8.60% |  400\n",
      "\t 37 | 00:04:32 (  7) |  0.10 | 128 | 30% | 1000 |  12.99% |  7.37% |  450 |  8.50% |  450\n",
      "\t 38 | 00:04:36 (  4) |  0.10 |   8 | 30% |  500 |  14.09% |  8.23% |  400 |  11.53% |  400\n",
      "\t 39 | 00:04:49 ( 13) |  0.30 | 128 | 95% |  500 |  21.07% |  15.01% |  250 |  20.59% |  250\n",
      "\t 40 | 00:04:55 (  6) |  0.30 | 128 | 30% | 1000 |  15.71% |  9.94% |  500 |  15.79% |  500\n",
      "\t 41 | 00:05:03 (  8) |  0.10 | 128 | 95% | 1000 |  14.16% |  9.93% |  400 |  12.07% |  500\n",
      "\t 42 | 00:05:06 (  2) |  0.30 |   4 | 30% | 1000 |   8.89% |  4.93% |   25 |  8.60% |   25\n",
      "\t 43 | 00:05:08 (  2) |  0.01 |   4 | 30% | 1000 |   5.89% |  4.37% |  500 |  6.72% |  150\n",
      "\t 44 | 00:05:11 (  3) |  0.30 |   4 | 95% |  500 |  12.79% |  8.82% |  500 |  13.48% |  400\n",
      "\t 45 | 00:05:17 (  6) |  0.10 |  32 | 60% | 1000 |  14.54% |  9.04% |  350 |  9.96% |  400\n",
      "\t 46 | 00:05:24 (  7) |  0.01 |  32 | 60% |  250 |  12.92% |  8.09% |  400 |  8.67% |  500\n",
      "\t 47 | 00:05:26 (  2) |  0.10 |   4 | 60% |  500 |  11.30% |  6.87% |  450 |  7.10% |  350\n",
      "\t 48 | 00:05:37 ( 10) |  0.30 | 128 | 30% |  250 |  21.81% |  15.17% |  500 |  25.83% |  500\n",
      "\t 49 | 00:05:39 (  2) |  0.01 |   4 | 60% |  500 |   5.39% |  3.47% |  200 |  3.42% |  450\n",
      "\t 50 | 00:05:41 (  2) |  0.30 |   4 | 60% |  250 |  12.15% |  9.06% |   25 |  7.73% |  500\n",
      "\t 51 | 00:05:48 (  7) |  0.01 | 128 | 60% |  500 |  14.10% |  10.04% |  500 |  9.46% |  500\n",
      "\t 52 | 00:05:50 (  2) |  0.30 |   8 | 30% |  250 |  12.43% |  8.54% |  450 |  12.41% |  400\n",
      "\t 53 | 00:05:53 (  2) |  0.01 |   4 | 60% | 1000 |   7.15% |  5.42% |  500 |  5.19% |  500\n",
      "Lookahead: 21 | Train: 756 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:06 (  6) |  0.01 |  32 | 30% |  500 |  14.12% |  7.60% |  500 |  3.93% |  100\n",
      "\t  1 | 00:00:09 (  3) |  0.30 |   8 | 30% | 1000 |  12.44% |  6.48% |  500 |  11.75% |  500\n",
      "\t  2 | 00:00:19 ( 10) |  0.01 |  32 | 95% |  250 |  11.44% |  6.23% |   25 |  6.38% |   25\n",
      "\t  3 | 00:00:24 (  5) |  0.10 |  32 | 30% | 1000 |  12.99% |  7.37% |  450 |  8.50% |  450\n",
      "\t  4 | 00:00:27 (  3) |  0.01 |   8 | 60% |  250 |   7.33% |  4.78% |  500 |  4.11% |  400\n",
      "\t  5 | 00:00:31 (  4) |  0.10 | 128 | 30% | 1000 |  12.99% |  7.37% |  450 |  8.50% |  450\n",
      "\t  6 | 00:00:33 (  2) |  0.30 |   4 | 30% | 1000 |   8.89% |  4.93% |   25 |  8.60% |   25\n",
      "\t  7 | 00:00:35 (  3) |  0.10 |   8 | 30% |  250 |  10.01% |  7.94% |  100 |  8.47% |   75\n",
      "\t  8 | 00:00:38 (  2) |  0.01 |   4 | 95% | 1000 |   6.23% |  5.08% |  450 |  6.72% |  450\n",
      "\t  9 | 00:00:40 (  2) |  0.30 |   4 | 95% |  250 |  10.54% |  8.21% |   75 |  11.24% |  300\n",
      "\t 10 | 00:00:43 (  3) |  0.10 |   8 | 60% |  250 |  12.50% |  8.62% |  500 |  7.83% |  500\n",
      "\t 11 | 00:00:49 (  6) |  0.01 |  32 | 95% | 1000 |   8.28% |  3.00% |  450 |  3.02% |  350\n",
      "\t 12 | 00:00:56 (  7) |  0.01 |  32 | 60% |  250 |  12.92% |  8.09% |  400 |  8.67% |  500\n",
      "\t 13 | 00:01:01 (  5) |  0.10 |  32 | 95% | 1000 |  14.16% |  9.93% |  400 |  12.07% |  500\n",
      "\t 14 | 00:01:05 (  3) |  0.30 |   8 | 95% |  500 |  15.34% |  10.96% |  150 |  13.83% |  300\n",
      "\t 15 | 00:01:12 (  8) |  0.30 |  32 | 95% |  250 |  24.95% |  20.55% |  450 |  22.98% |  350\n",
      "\t 16 | 00:01:21 (  9) |  0.01 |  32 | 95% |  500 |  12.97% |  7.91% |  500 |  6.09% |  200\n",
      "\t 17 | 00:01:27 (  7) |  0.10 |  32 | 30% |  500 |  14.88% |  7.81% |  500 |  10.42% |  100\n",
      "\t 18 | 00:01:30 (  2) |  0.10 |   4 | 95% |  500 |  10.76% |  8.01% |  300 |  7.81% |  300\n",
      "\t 19 | 00:01:32 (  2) |  0.01 |   8 | 30% |  250 |   8.76% |  6.41% |   75 |  11.50% |   75\n",
      "\t 20 | 00:01:36 (  4) |  0.01 |  32 | 30% | 1000 |  10.72% |  5.82% |  400 |  5.20% |  500\n",
      "\t 21 | 00:01:40 (  4) |  0.01 |   8 | 95% |  250 |   6.74% |  4.73% |  400 |  4.33% |  150\n",
      "\t 22 | 00:01:53 ( 13) |  0.30 | 128 | 30% |  250 |  21.81% |  15.17% |  500 |  25.83% |  500\n",
      "\t 23 | 00:01:56 (  3) |  0.10 |   8 | 95% |  250 |  12.68% |  8.08% |  300 |  7.60% |  300\n",
      "\t 24 | 00:01:59 (  3) |  0.01 |   8 | 30% | 1000 |   5.75% |  4.31% |   75 |  3.67% |  200\n",
      "\t 25 | 00:02:07 (  8) |  0.10 |  32 | 95% |  250 |  18.79% |  13.00% |  400 |  12.88% |  500\n",
      "\t 26 | 00:02:09 (  3) |  0.30 |   8 | 60% |  250 |  10.20% |  5.07% |  150 |  6.23% |  400\n",
      "\t 27 | 00:02:22 ( 12) |  0.30 | 128 | 60% |  250 |  19.73% |  15.87% |  400 |  21.26% |  500\n",
      "\t 28 | 00:02:24 (  3) |  0.10 |   8 | 30% |  500 |  14.09% |  8.23% |  400 |  11.53% |  400\n",
      "\t 29 | 00:02:31 (  7) |  0.30 | 128 | 60% |  500 |  20.97% |  14.99% |  200 |  22.93% |  450\n",
      "\t 30 | 00:05:56 (205) |  0.01 | 128 | 95% |  250 |  16.63% |  9.96% |  350 |  11.53% |  250\n",
      "\t 31 | 00:06:04 (  8) |  0.30 |  32 | 60% |  500 |  14.65% |  10.80% |  150 |  13.23% |  150\n",
      "\t 32 | 00:06:08 (  4) |  0.30 |   8 | 95% | 1000 |  12.49% |  7.70% |  200 |  13.74% |  500\n",
      "\t 33 | 00:06:17 (  9) |  0.01 | 128 | 95% |  500 |  13.63% |  8.30% |  500 |  6.41% |  150\n",
      "\t 34 | 00:06:25 (  8) |  0.10 |  32 | 95% |  500 |  18.92% |  12.17% |  500 |  18.03% |  400\n",
      "\t 35 | 00:06:30 (  5) |  0.01 | 128 | 30% | 1000 |  10.72% |  5.82% |  400 |  5.20% |  500\n",
      "\t 36 | 00:06:34 (  4) |  0.01 |   8 | 95% |  500 |   5.80% |  3.95% |  500 |  3.09% |  400\n",
      "\t 37 | 00:06:40 (  6) |  0.10 | 128 | 60% | 1000 |  14.54% |  9.04% |  350 |  9.96% |  400\n",
      "\t 38 | 00:06:50 ( 10) |  0.30 |  32 | 95% |  500 |  22.05% |  15.72% |  450 |  15.81% |  200\n",
      "\t 39 | 00:06:52 (  2) |  0.30 |   4 | 60% |  500 |  12.92% |  7.15% |  400 |  8.60% |  400\n",
      "\t 40 | 00:06:54 (  2) |  0.10 |   4 | 60% |  250 |   9.02% |  6.49% |  250 |  7.56% |  250\n",
      "\t 41 | 00:06:58 (  4) |  0.10 |   8 | 95% | 1000 |  10.83% |  5.80% |  300 |  9.20% |  300\n",
      "\t 42 | 00:07:11 ( 13) |  0.01 | 128 | 30% |  250 |  15.91% |  9.00% |  500 |  8.35% |  500\n",
      "\t 43 | 00:07:14 (  3) |  0.10 |   8 | 60% |  500 |  10.41% |  4.80% |  450 |  7.78% |  400\n",
      "\t 44 | 00:07:17 (  3) |  0.30 |   8 | 30% |  500 |  11.90% |  6.40% |  500 |  9.68% |  500\n",
      "\t 45 | 00:07:24 (  7) |  0.10 |  32 | 30% |  250 |  13.14% |  7.07% |   10 |  7.56% |  350\n",
      "\t 46 | 00:07:33 (  8) |  0.01 | 128 | 60% |  500 |  14.10% |  10.04% |  500 |  9.46% |  500\n",
      "\t 47 | 00:07:36 (  4) |  0.01 |   8 | 60% |  500 |   6.82% |  4.13% |   25 |  4.31% |   25\n",
      "\t 48 | 00:07:38 (  2) |  0.30 |   4 | 30% |  500 |  13.42% |  8.89% |  450 |  10.96% |  450\n",
      "\t 49 | 00:07:40 (  2) |  0.10 |   4 | 30% |  500 |   8.91% |  7.72% |  400 |  9.83% |  500\n",
      "\t 50 | 00:07:49 (  9) |  0.30 | 128 | 30% |  500 |  18.18% |  15.04% |  450 |  17.86% |  450\n",
      "\t 51 | 00:07:51 (  2) |  0.01 |   4 | 30% |  500 |   5.79% |  4.31% |  500 |  6.53% |   75\n",
      "\t 52 | 00:07:53 (  2) |  0.30 |   4 | 30% |  250 |  10.33% |  8.60% |   50 |  9.78% |   50\n",
      "\t 53 | 00:07:57 (  4) |  0.30 |   8 | 60% | 1000 |  15.46% |  10.68% |   50 |  13.75% |  450\n",
      "Lookahead:  1 | Train: 126 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:08 (  8) |  0.30 |  32 | 30% |  500 |   9.13% |  9.99% |   50 |  11.64% |  500\n",
      "\t  1 | 00:00:09 (  2) |  0.10 |   4 | 30% | 1000 |   4.37% |  0.04% |   75 |  3.18% |   75\n",
      "\t  2 | 00:00:12 (  2) |  0.01 |   4 | 95% | 1000 |   6.17% |  2.92% |  500 |  3.87% |  150\n",
      "\t  3 | 00:00:17 (  5) |  0.30 | 128 | 60% | 1000 |   0.42% | -1.96% |   25 |  0.70% |  500\n",
      "\t  4 | 00:00:19 (  2) |  0.30 |   4 | 30% | 1000 |   4.46% |  2.01% |   25 |  7.89% |   75\n",
      "\t  5 | 00:00:25 (  6) |  0.01 |  32 | 60% | 1000 |   3.61% | -1.19% |   25 |  0.41% |  400\n",
      "\t  6 | 00:00:30 (  5) |  0.01 | 128 | 30% | 1000 |   3.70% |  3.52% |   10 |  3.62% |   10\n",
      "\t  7 | 00:00:38 (  8) |  0.10 |  32 | 60% |  500 |   5.76% |  3.41% |  450 |  8.35% |   75\n",
      "\t  8 | 00:00:53 ( 15) |  0.01 | 128 | 95% |  250 |   3.49% |  2.63% |  500 |  2.98% |  400\n",
      "\t  9 | 00:00:60 (  7) |  0.10 |  32 | 95% | 1000 |   2.84% |  0.31% |  350 |  6.36% |  300\n",
      "\t 10 | 00:01:10 ( 10) |  0.01 |  32 | 60% |  250 |   3.82% | -0.15% |  450 |  1.01% |  450\n",
      "\t 11 | 00:01:12 (  2) |  0.10 |   4 | 60% | 1000 |   5.53% |  3.88% |   10 |  4.54% |   10\n",
      "\t 12 | 00:01:17 (  5) |  0.01 |  32 | 30% | 1000 |   3.70% |  3.52% |   10 |  3.62% |   10\n",
      "\t 13 | 00:01:20 (  3) |  0.10 |   4 | 95% | 1000 |   6.47% |  3.05% |   50 |  4.47% |  450\n",
      "\t 14 | 00:01:26 (  6) |  0.10 |  32 | 60% | 1000 |   3.71% | -0.70% |   25 |  0.30% |   50\n",
      "\t 15 | 00:01:34 (  8) |  0.10 | 128 | 30% |  500 |   8.01% |  6.69% |  450 |  9.91% |  400\n",
      "\t 16 | 00:01:37 (  4) |  0.30 |   8 | 95% | 1000 |   1.73% | -1.28% |  350 | -2.36% |   75\n",
      "\t 17 | 00:01:44 (  6) |  0.01 |  32 | 30% |  250 |   5.25% |  1.65% |   25 |  6.83% |  500\n",
      "\t 18 | 00:01:52 (  8) |  0.30 |  32 | 95% |  500 |   5.11% |  6.16% |  250 |  4.39% |  400\n",
      "\t 19 | 00:01:60 (  7) |  0.30 |  32 | 60% |  250 |   6.94% |  6.77% |   25 |  11.14% |   10\n",
      "\t 20 | 00:02:02 (  3) |  0.30 |   8 | 30% |  250 |   0.54% | -0.88% |   25 | -2.51% |   25\n",
      "\t 21 | 00:02:05 (  3) |  0.10 |   4 | 95% |  500 |   3.86% | -0.18% |   75 |  3.41% |  500\n",
      "\t 22 | 00:02:08 (  3) |  0.30 |   8 | 30% |  500 |   4.05% |  1.81% |   50 |  7.09% |   50\n",
      "\t 23 | 00:02:11 (  3) |  0.01 |   8 | 60% | 1000 |   6.19% |  3.35% |   25 |  3.36% |   25\n",
      "\t 24 | 00:02:13 (  2) |  0.01 |   4 | 30% | 1000 |   4.75% |  3.31% |   50 |  6.99% |   50\n",
      "\t 25 | 00:02:16 (  2) |  0.01 |   4 | 60% | 1000 |   6.82% |  4.38% |  500 |  3.36% |  250\n",
      "\t 26 | 00:02:19 (  3) |  0.10 |   8 | 60% |  500 |   4.83% |  2.38% |  100 |  4.92% |  100\n",
      "\t 27 | 00:02:31 ( 12) |  0.10 | 128 | 30% |  250 |   4.50% |  3.57% |  450 |  4.63% |   75\n",
      "\t 28 | 00:02:38 (  8) |  0.01 |  32 | 60% |  500 |   3.68% |  0.17% |  350 |  4.34% |  350\n",
      "\t 29 | 00:02:41 (  2) |  0.30 |   8 | 30% | 1000 |   4.49% | -0.75% |   10 |  0.91% |   25\n",
      "\t 30 | 00:02:45 (  4) |  0.30 |  32 | 30% | 1000 |   2.57% |  1.04% |  450 |  1.24% |  450\n",
      "\t 31 | 00:02:53 (  8) |  0.10 |  32 | 30% |  500 |   5.28% |  1.64% |   25 |  5.21% |   10\n",
      "\t 32 | 00:02:54 (  2) |  0.10 |   4 | 30% |  500 |   4.41% |  2.54% |   25 |  5.72% |  100\n",
      "\t 33 | 00:02:59 (  5) |  0.10 | 128 | 60% | 1000 |   3.71% | -0.70% |   25 |  0.30% |   50\n",
      "\t 34 | 00:03:11 ( 11) |  0.30 | 128 | 30% |  250 |   9.76% |  8.88% |   10 |  8.07% |   25\n",
      "\t 35 | 00:03:12 (  2) |  0.01 |   4 | 30% |  500 |   3.75% |  3.72% |   50 |  1.50% |  500\n",
      "\t 36 | 00:03:21 (  8) |  0.01 |  32 | 95% |  500 |   3.49% |  1.28% |  450 |  2.56% |  450\n",
      "\t 37 | 00:03:23 (  3) |  0.10 |   8 | 30% |  500 |   1.57% | -0.75% |   25 |  0.86% |   75\n",
      "\t 38 | 00:03:31 (  8) |  0.10 | 128 | 60% |  500 |   7.38% |  5.34% |  450 |  5.79% |   25\n",
      "\t 39 | 00:03:34 (  3) |  0.10 |   8 | 60% | 1000 |   6.44% |  2.63% |   50 |  4.29% |   25\n",
      "\t 40 | 00:03:37 (  3) |  0.01 |   8 | 60% |  250 |   6.07% |  3.16% |   25 |  3.10% |   25\n",
      "\t 41 | 00:03:39 (  2) |  0.30 |   4 | 95% | 1000 |   6.56% |  2.43% |   25 |  4.05% |   25\n",
      "\t 42 | 00:03:46 (  7) |  0.01 |  32 | 95% | 1000 |   4.15% | -1.34% |  300 |  0.44% |   10\n",
      "\t 43 | 00:03:48 (  2) |  0.30 |   4 | 95% |  500 |   3.25% |  1.47% |   75 |  5.75% |  300\n",
      "\t 44 | 00:03:50 (  2) |  0.30 |   4 | 30% |  250 |   2.01% |  0.99% |   25 |  3.72% |  250\n",
      "\t 45 | 00:03:54 (  4) |  0.10 |   8 | 95% |  250 |   6.16% |  3.27% |   10 |  2.32% |  300\n",
      "\t 46 | 00:04:03 (  9) |  0.01 | 128 | 60% |  500 |   5.39% |  1.35% |  400 |  4.80% |  500\n",
      "\t 47 | 00:04:07 (  4) |  0.10 | 128 | 30% | 1000 |   4.56% |  2.68% |   10 |  2.20% |   10\n",
      "\t 48 | 00:04:15 (  8) |  0.30 |  32 | 30% |  250 |   6.87% |  5.36% |  100 |  4.73% |  250\n",
      "\t 49 | 00:04:18 (  3) |  0.01 |   8 | 30% | 1000 |   3.14% |  2.72% |   25 |  7.27% |   25\n",
      "\t 50 | 00:04:22 (  4) |  0.10 |   8 | 95% |  500 |   6.11% |  1.57% |   50 |  3.73% |   50\n",
      "\t 51 | 00:04:26 (  4) |  0.10 |   8 | 95% | 1000 |   4.29% | -1.38% |  200 |  3.43% |   75\n",
      "\t 52 | 00:04:35 (  9) |  0.10 |  32 | 95% |  500 |   4.72% |  4.65% |  500 |  4.24% |  200\n",
      "\t 53 | 00:04:44 (  8) |  0.10 |  32 | 30% |  250 |   3.03% |  1.79% |  500 |  4.48% |   10\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=tables.exceptions.NaturalNameWarning)\n",
    "\n",
    "def format_time(t):\n",
    "    m, s = divmod(t, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f'{h:02.0f}:{m:02.0f}:{s:02.0f}'\n",
    "\n",
    "def get_fi(model):\n",
    "    return pd.Series(model.feature_importance(), index=model.feature_name())\n",
    "\n",
    "\n",
    "\n",
    "for lookahead, train_length, test_length in test_params:\n",
    "    # randomized grid search\n",
    "    cvp = np.random.choice(list(range(n_params)),\n",
    "                           size=int(n_params / 2),\n",
    "                           replace=False)\n",
    "    cv_params_ = [cv_params[i] for i in cvp]\n",
    "\n",
    "    # set up cross-validation\n",
    "    n_splits = int(2 * 252 / test_length)  # Assuming 252 trading days in a year\n",
    "    print(f'Lookahead: {lookahead:2.0f} | '\n",
    "          f'Train: {train_length:3.0f} | '\n",
    "          f'Test: {test_length:2.0f} | '\n",
    "          f'Params: {len(cv_params_):3.0f} | '\n",
    "          f'Train configs: {len(test_params)}')\n",
    "\n",
    "    # time-series cross-validation\n",
    "    cv = TimeSeriesSplit(n_splits=n_splits, test_size=test_length)\n",
    "\n",
    "    label = label_dict[lookahead]\n",
    "    feature_cols = [col for col in all_features.columns if col != label]\n",
    "    outcome_data = all_features.loc[:, feature_cols + [label]].dropna()\n",
    "    \n",
    "    T = 0\n",
    "    predictions, metrics, feature_importance, daily_ic = [], [], [], []\n",
    "    \n",
    "    # iterate over (shuffled) hyperparameter combinations\n",
    "    for p, param_vals in enumerate(cv_params_):\n",
    "        key = f'{lookahead}/{train_length}/{test_length}/' + '/'.join([str(p) for p in param_vals])\n",
    "        params = dict(zip(param_names, param_vals))\n",
    "        params.update(base_params)\n",
    "\n",
    "        start = time()\n",
    "        cv_preds, nrounds = [], []\n",
    "        ic_cv = defaultdict(list)\n",
    "        \n",
    "        # iterate over folds\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(outcome_data)):\n",
    "            \n",
    "            # select train subset\n",
    "            train_data = outcome_data.iloc[train_idx]\n",
    "            test_data = outcome_data.iloc[test_idx]\n",
    "            \n",
    "            lgb_train = lgb.Dataset(data=train_data[feature_cols],\n",
    "                                    label=train_data[label],\n",
    "                                    free_raw_data=False)\n",
    "            \n",
    "            # train model for num_boost_round\n",
    "            model = lgb.train(params=params,\n",
    "                              train_set=lgb_train,\n",
    "                              num_boost_round=num_boost_round,\n",
    "                              callbacks=[log_evaluation(period=0)])\n",
    "            \n",
    "            # log feature importance\n",
    "            if i == 0:\n",
    "                fi = get_fi(model).to_frame()\n",
    "            else:\n",
    "                fi[i] = get_fi(model)\n",
    "\n",
    "            # capture predictions\n",
    "            X_test = test_data[feature_cols]\n",
    "            y_test = test_data[label]\n",
    "            y_pred = {str(n): model.predict(X_test, num_iteration=n) for n in num_iterations}\n",
    "            \n",
    "            # record predictions for each fold\n",
    "            cv_preds.append(pd.DataFrame({'y_test': y_test, **y_pred, 'i': i}, index=test_data.index))\n",
    "        \n",
    "        # combine fold results\n",
    "        cv_preds = pd.concat(cv_preds).assign(**params)\n",
    "        predictions.append(cv_preds)\n",
    "        \n",
    "        # compute IC per day\n",
    "        by_day = cv_preds.groupby(level=0)\n",
    "        ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test, x[str(n)])[0]).to_frame(n)\n",
    "                               for n in num_iterations], axis=1)\n",
    "        daily_ic_mean = ic_by_day.mean()\n",
    "        daily_ic_mean_n = daily_ic_mean.idxmax()\n",
    "        daily_ic_median = ic_by_day.median()\n",
    "        daily_ic_median_n = daily_ic_median.idxmax()\n",
    "        \n",
    "        # compute IC across all predictions\n",
    "        ic = [spearmanr(cv_preds.y_test, cv_preds[str(n)])[0] for n in num_iterations]\n",
    "        t = time() - start\n",
    "        T += t\n",
    "        \n",
    "        # collect metrics\n",
    "        metrics = pd.Series(list(param_vals) +\n",
    "                            [t, daily_ic_mean.max(), daily_ic_mean_n, daily_ic_median.max(), daily_ic_median_n] + ic,\n",
    "                            index=metric_cols)\n",
    "        msg = f'\\t{p:3.0f} | {format_time(T)} ({t:3.0f}) | {params[\"learning_rate\"]:5.2f} | '\n",
    "        msg += f'{params[\"num_leaves\"]:3.0f} | {params[\"feature_fraction\"]:3.0%} | {params[\"min_data_in_leaf\"]:4.0f} | '\n",
    "        msg += f' {max(ic):6.2%} | {ic_by_day.mean().max(): 6.2%} | {daily_ic_mean_n: 4.0f} | {ic_by_day.median().max(): 6.2%} | {daily_ic_median_n: 4.0f}'\n",
    "        print(msg)\n",
    "\n",
    "        # persist results for given CV run and hyperparameter combination\n",
    "        metrics.to_hdf('lgb_results.h5', 'metrics/' + key)\n",
    "        ic_by_day.assign(**params).to_hdf('lgb_results.h5', 'daily_ic/' + key)\n",
    "        fi.T.describe().T.assign(**params).to_hdf('lgb_results.h5', 'fi/' + key)\n",
    "        cv_preds.to_hdf('lgb_results.h5', 'predictions/' + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4536 entries, 0 to 4535\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   lookahead          4536 non-null   int64  \n",
      " 1   train_length       4536 non-null   int64  \n",
      " 2   test_length        4536 non-null   int64  \n",
      " 3   learning_rate      4536 non-null   float64\n",
      " 4   num_leaves         4536 non-null   float64\n",
      " 5   feature_fraction   4536 non-null   float64\n",
      " 6   min_data_in_leaf   4536 non-null   float64\n",
      " 7   daily_ic_mean      4536 non-null   float64\n",
      " 8   daily_ic_mean_n    4536 non-null   float64\n",
      " 9   daily_ic_median    4536 non-null   float64\n",
      " 10  daily_ic_median_n  4536 non-null   float64\n",
      " 11  boost_rounds       4536 non-null   object \n",
      " 12  ic                 4536 non-null   float64\n",
      "dtypes: float64(9), int64(3), object(1)\n",
      "memory usage: 460.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lookahead  train_length  test_length\n",
       "1          126           63             54\n",
       "           756           63             54\n",
       "21         126           63             54\n",
       "           756           63             54\n",
       "5          126           63             54\n",
       "           756           63             54\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Adjust the path to match your current working directory\n",
    "results_path = Path('~/Projects/Algothon-24')\n",
    "lgb_metrics = []\n",
    "\n",
    "with pd.HDFStore(results_path / 'tuning_lgb.h5') as store:\n",
    "    for key in store.keys():\n",
    "        if key.startswith('/metrics'):\n",
    "            parts = key.split('/')\n",
    "            lookahead, train_length, test_length = parts[2:5]\n",
    "            \n",
    "            s = store[key]\n",
    "            s['lookahead'] = lookahead\n",
    "            s['train_length'] = train_length\n",
    "            s['test_length'] = test_length\n",
    "            \n",
    "            lgb_metrics.append(s)\n",
    "\n",
    "lgb_metrics = pd.DataFrame(lgb_metrics)\n",
    "\n",
    "# Define the columns as before\n",
    "scope_params = ['lookahead', 'train_length', 'test_length']\n",
    "daily_ic_metrics = ['daily_ic_mean', 'daily_ic_mean_n', 'daily_ic_median', 'daily_ic_median_n']\n",
    "lgb_train_params = ['learning_rate', 'num_leaves', 'feature_fraction', 'min_data_in_leaf']\n",
    "\n",
    "id_vars = scope_params + lgb_train_params + daily_ic_metrics\n",
    "\n",
    "# Melt the DataFrame\n",
    "lgb_metrics_melted = pd.melt(lgb_metrics, \n",
    "                             id_vars=id_vars, \n",
    "                             value_name='ic', \n",
    "                             var_name='boost_rounds').dropna()\n",
    "\n",
    "# Convert to numeric\n",
    "lgb_metrics_melted = lgb_metrics_melted.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Save to HDF5 in the same directory\n",
    "lgb_metrics_melted.to_hdf(results_path / 'model_tuning.h5', 'lgb/metrics')\n",
    "\n",
    "# Display info\n",
    "lgb_metrics_melted.info()\n",
    "lgb_metrics.groupby(scope_params).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before melt operation: [10, 25, 50, 75, 100, 150, 200, 250, 300, 350, 400, 450, 500, 'learning_rate', 'num_leaves', 'feature_fraction', 'min_data_in_leaf', 'lookahead', 'train_length', 'test_length']\n",
      "Columns after melt operation: ['lookahead', 'train_length', 'test_length', 'learning_rate', 'num_leaves', 'feature_fraction', 'min_data_in_leaf', 'boost_rounds', 'ic_value']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75816 entries, 0 to 75815\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   lookahead         75816 non-null  int64  \n",
      " 1   train_length      75816 non-null  int64  \n",
      " 2   test_length       75816 non-null  int64  \n",
      " 3   learning_rate     75816 non-null  float64\n",
      " 4   num_leaves        75816 non-null  int64  \n",
      " 5   feature_fraction  75816 non-null  float64\n",
      " 6   min_data_in_leaf  75816 non-null  int64  \n",
      " 7   boost_rounds      75816 non-null  int64  \n",
      " 8   ic_value          75816 non-null  float64\n",
      "dtypes: float64(3), int64(6)\n",
      "memory usage: 5.2 MB\n"
     ]
    }
   ],
   "source": [
    "int_cols = [\"lookahead\", \"train_length\", \"test_length\", \"boost_rounds\"]\n",
    "\n",
    "lgb_ic = []\n",
    "with pd.HDFStore(results_path / \"tuning_lgb.h5\") as store:\n",
    "    keys = [k[1:] for k in store.keys()]\n",
    "    for key in keys:\n",
    "        _, t, train_length, test_length = key.split(\"/\")[:4]\n",
    "        if key.startswith(\"daily_ic\"):\n",
    "            df = (\n",
    "                store[key]\n",
    "                .drop([\"boosting\", \"objective\", \"verbose\"], axis=1)\n",
    "                .assign(lookahead=t, train_length=train_length, test_length=test_length)\n",
    "            )\n",
    "            lgb_ic.append(df)\n",
    "    lgb_ic = pd.concat(lgb_ic).reset_index(drop=True)\n",
    "\n",
    "# Print columns before melt operation\n",
    "print(\"Columns before melt operation:\", lgb_ic.columns.tolist())\n",
    "\n",
    "id_vars = scope_params + lgb_train_params\n",
    "lgb_ic = pd.melt(\n",
    "    lgb_ic, id_vars=id_vars, value_name=\"ic_value\", var_name=\"boost_rounds\"\n",
    ").dropna()\n",
    "\n",
    "# Print columns after melt operation\n",
    "print(\"Columns after melt operation:\", lgb_ic.columns.tolist())\n",
    "\n",
    "# Ensure only the specified integer columns are converted to integers\n",
    "lgb_ic[int_cols] = lgb_ic[int_cols].astype(int)\n",
    "\n",
    "# Display info to check data types\n",
    "lgb_ic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4212 entries, 0 to 4211\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   lookahead         4212 non-null   int64  \n",
      " 1   train_length      4212 non-null   int64  \n",
      " 2   test_length       4212 non-null   int64  \n",
      " 3   learning_rate     4212 non-null   float64\n",
      " 4   num_leaves        4212 non-null   int64  \n",
      " 5   feature_fraction  4212 non-null   float64\n",
      " 6   min_data_in_leaf  4212 non-null   int64  \n",
      " 7   boost_rounds      4212 non-null   int64  \n",
      " 8   ic                4212 non-null   float64\n",
      "dtypes: float64(3), int64(6)\n",
      "memory usage: 296.3 KB\n"
     ]
    }
   ],
   "source": [
    "lgb_ic.to_hdf(\"model_tuning.h5\", \"lgb/ic\")\n",
    "lgb_daily_ic = (\n",
    "    lgb_ic.groupby(id_vars[0:] + [\"boost_rounds\"])[\"ic_value\"]\n",
    "    .mean()\n",
    "    .to_frame(\"ic\")\n",
    "    .reset_index()\n",
    ")\n",
    "lgb_daily_ic.to_hdf(\"model_tuning.h5\", \"lgb/daily_ic\")\n",
    "lgb_daily_ic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_ic = pd.read_hdf(\"model_tuning.h5\", \"lgb/ic\")\n",
    "lgb_daily_ic = pd.read_hdf(\"model_tuning.h5\", \"lgb/daily_ic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lookahead</th>\n",
       "      <th>train_length</th>\n",
       "      <th>test_length</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>boost_rounds</th>\n",
       "      <th>ic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>1</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "      <td>0.1</td>\n",
       "      <td>128</td>\n",
       "      <td>0.60</td>\n",
       "      <td>250</td>\n",
       "      <td>450</td>\n",
       "      <td>0.106148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>63</td>\n",
       "      <td>0.3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.30</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>0.099861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "      <td>0.3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.30</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>0.099861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "      <td>0.1</td>\n",
       "      <td>128</td>\n",
       "      <td>0.60</td>\n",
       "      <td>250</td>\n",
       "      <td>300</td>\n",
       "      <td>0.353721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "      <td>0.3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.95</td>\n",
       "      <td>250</td>\n",
       "      <td>300</td>\n",
       "      <td>0.352499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "      <td>0.1</td>\n",
       "      <td>128</td>\n",
       "      <td>0.60</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>0.351763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>21</td>\n",
       "      <td>126</td>\n",
       "      <td>63</td>\n",
       "      <td>0.3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.95</td>\n",
       "      <td>250</td>\n",
       "      <td>450</td>\n",
       "      <td>0.205537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>21</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "      <td>0.3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.95</td>\n",
       "      <td>250</td>\n",
       "      <td>450</td>\n",
       "      <td>0.205537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>21</td>\n",
       "      <td>126</td>\n",
       "      <td>63</td>\n",
       "      <td>0.3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.95</td>\n",
       "      <td>250</td>\n",
       "      <td>350</td>\n",
       "      <td>0.203173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lookahead  train_length  test_length  learning_rate  num_leaves  \\\n",
       "1181          1           756           63            0.1         128   \n",
       "626           1           126           63            0.3          32   \n",
       "1328          1           756           63            0.3          32   \n",
       "2595          5           756           63            0.1         128   \n",
       "2764          5           756           63            0.3          32   \n",
       "2599          5           756           63            0.1         128   \n",
       "3443         21           126           63            0.3          32   \n",
       "4145         21           756           63            0.3          32   \n",
       "3441         21           126           63            0.3          32   \n",
       "\n",
       "      feature_fraction  min_data_in_leaf  boost_rounds        ic  \n",
       "1181              0.60               250           450  0.106148  \n",
       "626               0.30               500            50  0.099861  \n",
       "1328              0.30               500            50  0.099861  \n",
       "2595              0.60               250           300  0.353721  \n",
       "2764              0.95               250           300  0.352499  \n",
       "2599              0.60               250           500  0.351763  \n",
       "3443              0.95               250           450  0.205537  \n",
       "4145              0.95               250           450  0.205537  \n",
       "3441              0.95               250           350  0.203173  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cols = scope_params + lgb_train_params + [\"boost_rounds\"]\n",
    "lgb_daily_ic.groupby(\"lookahead\", group_keys=False).apply(lambda x: x.nlargest(3, \"ic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>min_data_in_leaf</th>\n",
       "      <th>t</th>\n",
       "      <th>daily_ic_mean</th>\n",
       "      <th>daily_ic_mean_n</th>\n",
       "      <th>daily_ic_median</th>\n",
       "      <th>daily_ic_median_n</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>200</th>\n",
       "      <th>250</th>\n",
       "      <th>300</th>\n",
       "      <th>350</th>\n",
       "      <th>400</th>\n",
       "      <th>450</th>\n",
       "      <th>500</th>\n",
       "      <th>lookahead</th>\n",
       "      <th>train_length</th>\n",
       "      <th>test_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.1</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>250.0</td>\n",
       "      <td>11.985325</td>\n",
       "      <td>0.106148</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.103941</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.048763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>0.100927</td>\n",
       "      <td>0.100756</td>\n",
       "      <td>0.097479</td>\n",
       "      <td>0.109097</td>\n",
       "      <td>0.115345</td>\n",
       "      <td>0.118527</td>\n",
       "      <td>1</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>500.0</td>\n",
       "      <td>10.209575</td>\n",
       "      <td>0.099861</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.116430</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.028331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049328</td>\n",
       "      <td>0.064375</td>\n",
       "      <td>0.044472</td>\n",
       "      <td>0.053361</td>\n",
       "      <td>0.057040</td>\n",
       "      <td>0.056675</td>\n",
       "      <td>0.067342</td>\n",
       "      <td>1</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>500.0</td>\n",
       "      <td>7.694120</td>\n",
       "      <td>0.099861</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.116430</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.028331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049328</td>\n",
       "      <td>0.064375</td>\n",
       "      <td>0.044472</td>\n",
       "      <td>0.053361</td>\n",
       "      <td>0.057040</td>\n",
       "      <td>0.056675</td>\n",
       "      <td>0.067342</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>250.0</td>\n",
       "      <td>7.543531</td>\n",
       "      <td>0.205537</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.229803</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.088488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211297</td>\n",
       "      <td>0.228528</td>\n",
       "      <td>0.224222</td>\n",
       "      <td>0.249544</td>\n",
       "      <td>0.248268</td>\n",
       "      <td>0.246807</td>\n",
       "      <td>0.247978</td>\n",
       "      <td>21</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>250.0</td>\n",
       "      <td>12.974158</td>\n",
       "      <td>0.205537</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.229803</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.088488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211297</td>\n",
       "      <td>0.228528</td>\n",
       "      <td>0.224222</td>\n",
       "      <td>0.249544</td>\n",
       "      <td>0.248268</td>\n",
       "      <td>0.246807</td>\n",
       "      <td>0.247978</td>\n",
       "      <td>21</td>\n",
       "      <td>126</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.3</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>250.0</td>\n",
       "      <td>12.098642</td>\n",
       "      <td>0.158676</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.212562</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.053863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165310</td>\n",
       "      <td>0.178621</td>\n",
       "      <td>0.181382</td>\n",
       "      <td>0.190168</td>\n",
       "      <td>0.189948</td>\n",
       "      <td>0.193071</td>\n",
       "      <td>0.197347</td>\n",
       "      <td>21</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.1</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>250.0</td>\n",
       "      <td>14.996168</td>\n",
       "      <td>0.353721</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.394335</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310533</td>\n",
       "      <td>0.318786</td>\n",
       "      <td>0.329287</td>\n",
       "      <td>0.328029</td>\n",
       "      <td>0.328800</td>\n",
       "      <td>0.329765</td>\n",
       "      <td>0.338409</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>250.0</td>\n",
       "      <td>12.161077</td>\n",
       "      <td>0.352499</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.359360</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.199265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317805</td>\n",
       "      <td>0.324196</td>\n",
       "      <td>0.329401</td>\n",
       "      <td>0.310951</td>\n",
       "      <td>0.317389</td>\n",
       "      <td>0.313458</td>\n",
       "      <td>0.318716</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>500.0</td>\n",
       "      <td>13.084522</td>\n",
       "      <td>0.346767</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.335961</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.164549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301521</td>\n",
       "      <td>0.318040</td>\n",
       "      <td>0.333633</td>\n",
       "      <td>0.330160</td>\n",
       "      <td>0.330193</td>\n",
       "      <td>0.331536</td>\n",
       "      <td>0.332182</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     learning_rate  num_leaves  feature_fraction  min_data_in_leaf          t  \\\n",
       "247            0.1       128.0              0.60             250.0  11.985325   \n",
       "228            0.3        32.0              0.30             500.0  10.209575   \n",
       "282            0.3        32.0              0.30             500.0   7.694120   \n",
       "119            0.3        32.0              0.95             250.0   7.543531   \n",
       "173            0.3        32.0              0.95             250.0  12.974158   \n",
       "122            0.3       128.0              0.60             250.0  12.098642   \n",
       "31             0.1       128.0              0.60             250.0  14.996168   \n",
       "8              0.3        32.0              0.95             250.0  12.161077   \n",
       "9              0.3        32.0              0.95             500.0  13.084522   \n",
       "\n",
       "     daily_ic_mean  daily_ic_mean_n  daily_ic_median  daily_ic_median_n  \\\n",
       "247       0.106148            450.0         0.103941              100.0   \n",
       "228       0.099861             50.0         0.116430              500.0   \n",
       "282       0.099861             50.0         0.116430              500.0   \n",
       "119       0.205537            450.0         0.229803              350.0   \n",
       "173       0.205537            450.0         0.229803              350.0   \n",
       "122       0.158676            400.0         0.212562              500.0   \n",
       "31        0.353721            300.0         0.394335              500.0   \n",
       "8         0.352499            300.0         0.359360              300.0   \n",
       "9         0.346767            300.0         0.335961              250.0   \n",
       "\n",
       "           10  ...       200       250       300       350       400  \\\n",
       "247  0.048763  ...  0.091598  0.100927  0.100756  0.097479  0.109097   \n",
       "228  0.028331  ...  0.049328  0.064375  0.044472  0.053361  0.057040   \n",
       "282  0.028331  ...  0.049328  0.064375  0.044472  0.053361  0.057040   \n",
       "119  0.088488  ...  0.211297  0.228528  0.224222  0.249544  0.248268   \n",
       "173  0.088488  ...  0.211297  0.228528  0.224222  0.249544  0.248268   \n",
       "122  0.053863  ...  0.165310  0.178621  0.181382  0.190168  0.189948   \n",
       "31   0.145222  ...  0.310533  0.318786  0.329287  0.328029  0.328800   \n",
       "8    0.199265  ...  0.317805  0.324196  0.329401  0.310951  0.317389   \n",
       "9    0.164549  ...  0.301521  0.318040  0.333633  0.330160  0.330193   \n",
       "\n",
       "          450       500  lookahead  train_length  test_length  \n",
       "247  0.115345  0.118527          1           756           63  \n",
       "228  0.056675  0.067342          1           756           63  \n",
       "282  0.056675  0.067342          1           126           63  \n",
       "119  0.246807  0.247978         21           756           63  \n",
       "173  0.246807  0.247978         21           126           63  \n",
       "122  0.193071  0.197347         21           756           63  \n",
       "31   0.329765  0.338409          5           756           63  \n",
       "8    0.313458  0.318716          5           756           63  \n",
       "9    0.331536  0.332182          5           756           63  \n",
       "\n",
       "[9 rows x 25 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_metrics.groupby('lookahead', group_keys=False).apply(lambda x: x.nlargest(3, 'daily_ic_mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_length        126.0\n",
      "test_length          63.0\n",
      "learning_rate         0.3\n",
      "num_leaves           32.0\n",
      "feature_fraction      0.3\n",
      "min_data_in_leaf    500.0\n",
      "boost_rounds         50.0\n",
      "Name: 626, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def get_lgb_params(data, t=5, best=0):\n",
    "    param_cols = scope_params[1:] + lgb_train_params + [\"boost_rounds\"]\n",
    "    df = data[data.lookahead == t].sort_values(\"ic\", ascending=False).iloc[best]\n",
    "    return df.loc[param_cols]\n",
    "\n",
    "best_params = get_lgb_params(lgb_daily_ic, t=1, best=1)\n",
    "\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m     fi \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\n\u001b[1;32m      3\u001b[0m         model\u001b[38;5;241m.\u001b[39mfeature_importance(importance_type\u001b[38;5;241m=\u001b[39mimportance_type),\n\u001b[1;32m      4\u001b[0m         index\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfeature_name(),\n\u001b[1;32m      5\u001b[0m     )\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fi \u001b[38;5;241m/\u001b[39m fi\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      9\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 10\u001b[0m     get_feature_importance(lgb_model)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mto_frame(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mjoin(get_feature_importance(lgb_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto_frame(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGain\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m (\n\u001b[1;32m     15\u001b[0m     feature_importance\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;241m20\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGain\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormalized Importance (Top 20 Features)\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "def get_feature_importance(model, importance_type=\"split\"):\n",
    "    fi = pd.Series(\n",
    "        model.feature_importance(importance_type=importance_type),\n",
    "        index=model.feature_name(),\n",
    "    )\n",
    "    return fi / fi.sum()\n",
    "\n",
    "\n",
    "feature_importance = (\n",
    "    get_feature_importance(lgb_model)\n",
    "    .to_frame(\"Split\")\n",
    "    .join(get_feature_importance(lgb_model, \"gain\").to_frame(\"Gain\"))\n",
    ")\n",
    "(\n",
    "    feature_importance.nlargest(20, columns=\"Gain\")\n",
    "    .sort_values(\"Gain\", ascending=False)\n",
    "    .plot.bar(\n",
    "        subplots=True, layout=(2, 1), figsize=(14, 6), legend=False, sharey=True, rot=0\n",
    "    )\n",
    ")\n",
    "plt.suptitle(\"Normalized Importance (Top 20 Features)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
